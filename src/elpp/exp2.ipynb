{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/smaug/ownCloud/praca/reasonable-embeddings/src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_dir = Path('../local/out/elpp/')\n",
    "\n",
    "base_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import lzma\n",
    "import dill\n",
    "\n",
    "with lzma.open(base_dir / 'reasoners.dill.xz', 'rb') as f:\n",
    "    reasoners = dill.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from src.reasoner import ReasonerHead\n",
    "from src.reasoner import EmbeddingLayer\n",
    "\n",
    "with lzma.open(base_dir / 'exp1.dill.xz', 'rb') as f:\n",
    "    artifacts = dill.load(f)\n",
    "\n",
    "emb_size = 10\n",
    "hidden_size = 16\n",
    "\n",
    "for key, components in artifacts.items():\n",
    "    neural_reasoner = ReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "    neural_reasoner.load_state_dict(components['reasoner'])\n",
    "    components['reasoner'] = neural_reasoner\n",
    "    encoders = [EmbeddingLayer(emb_size=emb_size, n_concepts=reasoner.n_concepts, n_roles=reasoner.n_roles) for reasoner in\n",
    "                reasoners]\n",
    "    for sd, e in zip(artifacts['encoders'], encoders):\n",
    "        e.load_state_dict(sd)\n",
    "    artifacts['encoders'] = encoders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:17<00:00, 17.19it/s]  \n",
      "100%|██████████| 300/300 [00:06<00:00, 47.08it/s]  \n",
      "100%|██████████| 300/300 [00:40<00:00,  7.48it/s]  \n",
      " 76%|███████▋  | 229/300 [00:00<00:00, 835.56it/s] \n",
      "100%|██████████| 300/300 [00:12<00:00, 24.22it/s]  \n",
      " 78%|███████▊  | 234/300 [00:00<00:00, 649.61it/s] \n",
      " 71%|███████   | 213/300 [00:00<00:00, 614.61it/s] \n",
      " 71%|███████   | 213/300 [00:00<00:00, 852.56it/s] \n",
      "100%|██████████| 300/300 [00:34<00:00,  8.73it/s]  \n",
      " 80%|████████  | 240/300 [00:00<00:00, 799.27it/s] \n",
      " 61%|██████▏   | 184/300 [00:00<00:00, 1024.46it/s]\n",
      "100%|██████████| 300/300 [00:57<00:00,  5.23it/s]  \n",
      "100%|██████████| 300/300 [00:21<00:00, 13.70it/s]  \n",
      " 80%|████████  | 241/300 [00:00<00:00, 725.77it/s] \n",
      " 67%|██████▋   | 202/300 [00:00<00:00, 807.05it/s] \n",
      " 59%|█████▉    | 177/300 [00:00<00:00, 1122.24it/s]\n",
      "100%|██████████| 300/300 [00:24<00:00, 12.12it/s]  \n",
      "100%|██████████| 300/300 [00:33<00:00,  9.07it/s]  \n",
      " 67%|██████▋   | 202/300 [00:00<00:00, 594.95it/s] \n",
      " 78%|███████▊  | 235/300 [00:00<00:00, 659.74it/s] \n",
      " 94%|█████████▎| 281/300 [00:00<00:00, 468.53it/s]\n",
      "100%|██████████| 300/300 [00:21<00:00, 14.26it/s]  \n",
      " 74%|███████▎  | 221/300 [00:00<00:00, 975.09it/s] \n",
      " 82%|████████▏ | 245/300 [00:00<00:00, 693.31it/s] \n",
      " 84%|████████▍ | 252/300 [00:00<00:00, 326.06it/s] \n",
      " 59%|█████▊    | 176/300 [00:00<00:00, 1095.73it/s]\n",
      "100%|██████████| 300/300 [00:47<00:00,  6.34it/s]  \n",
      " 80%|████████  | 241/300 [00:01<00:00, 130.25it/s] \n",
      " 68%|██████▊   | 204/300 [00:00<00:00, 877.54it/s] \n",
      "100%|██████████| 300/300 [00:37<00:00,  7.95it/s]  \n",
      " 81%|████████  | 243/300 [00:00<00:00, 754.03it/s] \n",
      " 63%|██████▎   | 190/300 [00:00<00:00, 906.09it/s] \n"
     ]
    }
   ],
   "source": [
    "with lzma.open(base_dir / 'test_reasoners.dill.xz', 'rb') as f:\n",
    "    test_reasoners = dill.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "best_neural_reasoner = artifacts[max(artifacts.keys())]['reasoner']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity threshold 2\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 320/319 | loss 0.7227 | val loss 0.7290 | acc 0.6946 | f1 0.6698 | prec 0.7291 | recall 0.6195 | roc auc 0.7678 | pr auc 0.8086 | elapsed 1.47s\n",
      "train epoch 01/15 | batch 320/319 | loss 0.7115 | val loss 0.7021 | acc 0.7037 | f1 0.6792 | prec 0.7404 | recall 0.6274 | roc auc 0.7765 | pr auc 0.8148 | elapsed 2.69s\n",
      "train epoch 02/15 | batch 320/319 | loss 0.6615 | val loss 0.6762 | acc 0.7104 | f1 0.6856 | prec 0.7500 | recall 0.6313 | roc auc 0.7847 | pr auc 0.8211 | elapsed 2.73s\n",
      "train epoch 03/15 | batch 320/319 | loss 0.6134 | val loss 0.6537 | acc 0.7144 | f1 0.6891 | prec 0.7561 | recall 0.6329 | roc auc 0.7922 | pr auc 0.8269 | elapsed 2.70s\n",
      "train epoch 04/15 | batch 320/319 | loss 0.5696 | val loss 0.6342 | acc 0.7223 | f1 0.6969 | prec 0.7671 | recall 0.6384 | roc auc 0.7990 | pr auc 0.8323 | elapsed 2.79s\n",
      "train epoch 05/15 | batch 320/319 | loss 0.5299 | val loss 0.6169 | acc 0.7298 | f1 0.7042 | prec 0.7780 | recall 0.6432 | roc auc 0.8055 | pr auc 0.8373 | elapsed 2.73s\n",
      "train epoch 06/15 | batch 320/319 | loss 0.4937 | val loss 0.6016 | acc 0.7350 | f1 0.7097 | prec 0.7845 | recall 0.6479 | roc auc 0.8114 | pr auc 0.8418 | elapsed 2.83s\n",
      "train epoch 07/15 | batch 320/319 | loss 0.4604 | val loss 0.5883 | acc 0.7342 | f1 0.7091 | prec 0.7830 | recall 0.6479 | roc auc 0.8168 | pr auc 0.8458 | elapsed 3.02s\n",
      "train epoch 08/15 | batch 320/319 | loss 0.4301 | val loss 0.5764 | acc 0.7358 | f1 0.7106 | prec 0.7854 | recall 0.6487 | roc auc 0.8217 | pr auc 0.8495 | elapsed 3.04s\n",
      "train epoch 09/15 | batch 320/319 | loss 0.4020 | val loss 0.5658 | acc 0.7409 | f1 0.7163 | prec 0.7914 | recall 0.6543 | roc auc 0.8263 | pr auc 0.8529 | elapsed 2.96s\n",
      "train epoch 10/15 | batch 320/319 | loss 0.3762 | val loss 0.5567 | acc 0.7437 | f1 0.7200 | prec 0.7933 | recall 0.6590 | roc auc 0.8303 | pr auc 0.8559 | elapsed 2.87s\n",
      "train epoch 11/15 | batch 320/319 | loss 0.3524 | val loss 0.5483 | acc 0.7476 | f1 0.7252 | prec 0.7958 | recall 0.6661 | roc auc 0.8340 | pr auc 0.8587 | elapsed 2.91s\n",
      "train epoch 12/15 | batch 320/319 | loss 0.3303 | val loss 0.5414 | acc 0.7476 | f1 0.7257 | prec 0.7947 | recall 0.6677 | roc auc 0.8372 | pr auc 0.8611 | elapsed 2.87s\n",
      "train epoch 13/15 | batch 320/319 | loss 0.3098 | val loss 0.5352 | acc 0.7516 | f1 0.7302 | prec 0.7989 | recall 0.6725 | roc auc 0.8402 | pr auc 0.8634 | elapsed 3.03s\n",
      "train epoch 14/15 | batch 320/319 | loss 0.2909 | val loss 0.5300 | acc 0.7540 | f1 0.7335 | prec 0.8000 | recall 0.6772 | roc auc 0.8429 | pr auc 0.8655 | elapsed 3.03s\n",
      "train epoch 15/15 | batch 320/319 | loss 0.2735 | val loss 0.5252 | acc 0.7536 | f1 0.7339 | prec 0.7976 | recall 0.6796 | roc auc 0.8456 | pr auc 0.8675 | elapsed 2.85s\n",
      "Complexity threshold 3\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 361/360 | loss 0.7905 | val loss 0.7395 | acc 0.7055 | f1 0.6752 | prec 0.7528 | recall 0.6120 | roc auc 0.7643 | pr auc 0.8102 | elapsed 1.68s\n",
      "train epoch 01/15 | batch 361/360 | loss 0.7721 | val loss 0.7040 | acc 0.7160 | f1 0.6868 | prec 0.7657 | recall 0.6225 | roc auc 0.7766 | pr auc 0.8188 | elapsed 3.15s\n",
      "train epoch 02/15 | batch 361/360 | loss 0.7076 | val loss 0.6726 | acc 0.7248 | f1 0.6956 | prec 0.7782 | recall 0.6289 | roc auc 0.7873 | pr auc 0.8267 | elapsed 3.20s\n",
      "train epoch 03/15 | batch 361/360 | loss 0.6476 | val loss 0.6451 | acc 0.7321 | f1 0.7041 | prec 0.7865 | recall 0.6373 | roc auc 0.7972 | pr auc 0.8340 | elapsed 3.21s\n",
      "train epoch 04/15 | batch 361/360 | loss 0.5939 | val loss 0.6210 | acc 0.7384 | f1 0.7115 | prec 0.7933 | recall 0.6450 | roc auc 0.8062 | pr auc 0.8409 | elapsed 3.23s\n",
      "train epoch 05/15 | batch 361/360 | loss 0.5448 | val loss 0.6001 | acc 0.7440 | f1 0.7187 | prec 0.7976 | recall 0.6541 | roc auc 0.8143 | pr auc 0.8471 | elapsed 3.44s\n",
      "train epoch 06/15 | batch 361/360 | loss 0.5018 | val loss 0.5811 | acc 0.7475 | f1 0.7245 | prec 0.7973 | recall 0.6639 | roc auc 0.8218 | pr auc 0.8527 | elapsed 3.38s\n",
      "train epoch 07/15 | batch 361/360 | loss 0.4615 | val loss 0.5648 | acc 0.7532 | f1 0.7324 | prec 0.7995 | recall 0.6758 | roc auc 0.8284 | pr auc 0.8578 | elapsed 3.13s\n",
      "train epoch 08/15 | batch 361/360 | loss 0.4261 | val loss 0.5503 | acc 0.7549 | f1 0.7356 | prec 0.7984 | recall 0.6821 | roc auc 0.8345 | pr auc 0.8624 | elapsed 3.23s\n",
      "train epoch 09/15 | batch 361/360 | loss 0.3941 | val loss 0.5376 | acc 0.7581 | f1 0.7395 | prec 0.8008 | recall 0.6870 | roc auc 0.8401 | pr auc 0.8667 | elapsed 3.12s\n",
      "train epoch 10/15 | batch 361/360 | loss 0.3642 | val loss 0.5264 | acc 0.7609 | f1 0.7431 | prec 0.8026 | recall 0.6919 | roc auc 0.8451 | pr auc 0.8704 | elapsed 3.29s\n",
      "train epoch 11/15 | batch 361/360 | loss 0.3376 | val loss 0.5167 | acc 0.7633 | f1 0.7474 | prec 0.8013 | recall 0.7003 | roc auc 0.8497 | pr auc 0.8738 | elapsed 3.22s\n",
      "train epoch 12/15 | batch 361/360 | loss 0.3134 | val loss 0.5083 | acc 0.7693 | f1 0.7546 | prec 0.8059 | recall 0.7094 | roc auc 0.8538 | pr auc 0.8769 | elapsed 3.22s\n",
      "train epoch 13/15 | batch 361/360 | loss 0.2918 | val loss 0.5013 | acc 0.7731 | f1 0.7595 | prec 0.8081 | recall 0.7164 | roc auc 0.8574 | pr auc 0.8795 | elapsed 3.19s\n",
      "train epoch 14/15 | batch 361/360 | loss 0.2717 | val loss 0.4952 | acc 0.7770 | f1 0.7642 | prec 0.8107 | recall 0.7227 | roc auc 0.8606 | pr auc 0.8818 | elapsed 3.21s\n",
      "train epoch 15/15 | batch 361/360 | loss 0.2536 | val loss 0.4903 | acc 0.7787 | f1 0.7670 | prec 0.8100 | recall 0.7283 | roc auc 0.8634 | pr auc 0.8838 | elapsed 3.26s\n",
      "Complexity threshold 4\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 402/401 | loss 0.8338 | val loss 0.8573 | acc 0.6655 | f1 0.6257 | prec 0.7103 | recall 0.5590 | roc auc 0.7215 | pr auc 0.7710 | elapsed 1.78s\n",
      "train epoch 01/15 | batch 402/401 | loss 0.8077 | val loss 0.8030 | acc 0.6753 | f1 0.6367 | prec 0.7225 | recall 0.5691 | roc auc 0.7391 | pr auc 0.7834 | elapsed 4.17s\n",
      "train epoch 02/15 | batch 402/401 | loss 0.7280 | val loss 0.7531 | acc 0.6840 | f1 0.6468 | prec 0.7333 | recall 0.5785 | roc auc 0.7557 | pr auc 0.7960 | elapsed 3.59s\n",
      "train epoch 03/15 | batch 402/401 | loss 0.6550 | val loss 0.7089 | acc 0.6976 | f1 0.6632 | prec 0.7482 | recall 0.5955 | roc auc 0.7713 | pr auc 0.8081 | elapsed 3.44s\n",
      "train epoch 04/15 | batch 402/401 | loss 0.5901 | val loss 0.6716 | acc 0.7063 | f1 0.6750 | prec 0.7556 | recall 0.6099 | roc auc 0.7850 | pr auc 0.8191 | elapsed 3.49s\n",
      "train epoch 05/15 | batch 402/401 | loss 0.5336 | val loss 0.6395 | acc 0.7177 | f1 0.6895 | prec 0.7659 | recall 0.6269 | roc auc 0.7974 | pr auc 0.8289 | elapsed 3.55s\n",
      "train epoch 06/15 | batch 402/401 | loss 0.4835 | val loss 0.6116 | acc 0.7264 | f1 0.7004 | prec 0.7741 | recall 0.6394 | roc auc 0.8086 | pr auc 0.8377 | elapsed 3.75s\n",
      "train epoch 07/15 | batch 402/401 | loss 0.4393 | val loss 0.5875 | acc 0.7374 | f1 0.7151 | prec 0.7817 | recall 0.6589 | roc auc 0.8187 | pr auc 0.8456 | elapsed 3.69s\n",
      "train epoch 08/15 | batch 402/401 | loss 0.4004 | val loss 0.5670 | acc 0.7443 | f1 0.7239 | prec 0.7869 | recall 0.6702 | roc auc 0.8276 | pr auc 0.8524 | elapsed 4.19s\n",
      "train epoch 09/15 | batch 402/401 | loss 0.3661 | val loss 0.5493 | acc 0.7503 | f1 0.7315 | prec 0.7911 | recall 0.6803 | roc auc 0.8354 | pr auc 0.8583 | elapsed 3.59s\n",
      "train epoch 10/15 | batch 402/401 | loss 0.3353 | val loss 0.5343 | acc 0.7560 | f1 0.7383 | prec 0.7959 | recall 0.6884 | roc auc 0.8424 | pr auc 0.8637 | elapsed 3.69s\n",
      "train epoch 11/15 | batch 402/401 | loss 0.3085 | val loss 0.5219 | acc 0.7604 | f1 0.7437 | prec 0.7993 | recall 0.6954 | roc auc 0.8485 | pr auc 0.8683 | elapsed 3.48s\n",
      "train epoch 12/15 | batch 402/401 | loss 0.2849 | val loss 0.5113 | acc 0.7663 | f1 0.7512 | prec 0.8033 | recall 0.7054 | roc auc 0.8538 | pr auc 0.8723 | elapsed 3.41s\n",
      "train epoch 13/15 | batch 402/401 | loss 0.2637 | val loss 0.5025 | acc 0.7673 | f1 0.7542 | prec 0.7990 | recall 0.7142 | roc auc 0.8585 | pr auc 0.8758 | elapsed 3.70s\n",
      "train epoch 14/15 | batch 402/401 | loss 0.2451 | val loss 0.4955 | acc 0.7726 | f1 0.7615 | prec 0.8006 | recall 0.7261 | roc auc 0.8625 | pr auc 0.8787 | elapsed 3.81s\n",
      "train epoch 15/15 | batch 402/401 | loss 0.2284 | val loss 0.4896 | acc 0.7776 | f1 0.7677 | prec 0.8036 | recall 0.7349 | roc auc 0.8662 | pr auc 0.8814 | elapsed 3.84s\n",
      "Complexity threshold 5\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 437/436 | loss 0.8705 | val loss 0.8602 | acc 0.6594 | f1 0.6100 | prec 0.7133 | recall 0.5329 | roc auc 0.7082 | pr auc 0.7639 | elapsed 2.04s\n",
      "train epoch 01/15 | batch 437/436 | loss 0.8390 | val loss 0.7944 | acc 0.6787 | f1 0.6333 | prec 0.7375 | recall 0.5548 | roc auc 0.7308 | pr auc 0.7809 | elapsed 3.79s\n",
      "train epoch 02/15 | batch 437/436 | loss 0.7495 | val loss 0.7363 | acc 0.6946 | f1 0.6538 | prec 0.7545 | recall 0.5768 | roc auc 0.7515 | pr auc 0.7972 | elapsed 3.76s\n",
      "train epoch 03/15 | batch 437/436 | loss 0.6692 | val loss 0.6865 | acc 0.7090 | f1 0.6727 | prec 0.7685 | recall 0.5982 | roc auc 0.7703 | pr auc 0.8121 | elapsed 3.83s\n",
      "train epoch 04/15 | batch 437/436 | loss 0.5991 | val loss 0.6440 | acc 0.7223 | f1 0.6899 | prec 0.7810 | recall 0.6178 | roc auc 0.7870 | pr auc 0.8255 | elapsed 3.77s\n",
      "train epoch 05/15 | batch 437/436 | loss 0.5379 | val loss 0.6076 | acc 0.7301 | f1 0.6993 | prec 0.7894 | recall 0.6276 | roc auc 0.8020 | pr auc 0.8374 | elapsed 4.14s\n",
      "train epoch 06/15 | batch 437/436 | loss 0.4840 | val loss 0.5764 | acc 0.7405 | f1 0.7140 | prec 0.7952 | recall 0.6478 | roc auc 0.8154 | pr auc 0.8478 | elapsed 4.18s\n",
      "train epoch 07/15 | batch 437/436 | loss 0.4372 | val loss 0.5492 | acc 0.7509 | f1 0.7265 | prec 0.8053 | recall 0.6617 | roc auc 0.8278 | pr auc 0.8572 | elapsed 4.24s\n",
      "train epoch 08/15 | batch 437/436 | loss 0.3965 | val loss 0.5263 | acc 0.7618 | f1 0.7403 | prec 0.8138 | recall 0.6790 | roc auc 0.8386 | pr auc 0.8652 | elapsed 4.36s\n",
      "train epoch 09/15 | batch 437/436 | loss 0.3609 | val loss 0.5068 | acc 0.7682 | f1 0.7498 | prec 0.8145 | recall 0.6946 | roc auc 0.8481 | pr auc 0.8723 | elapsed 4.33s\n",
      "train epoch 10/15 | batch 437/436 | loss 0.3300 | val loss 0.4903 | acc 0.7751 | f1 0.7598 | prec 0.8154 | recall 0.7113 | roc auc 0.8565 | pr auc 0.8785 | elapsed 4.04s\n",
      "train epoch 11/15 | batch 437/436 | loss 0.3031 | val loss 0.4764 | acc 0.7789 | f1 0.7647 | prec 0.8169 | recall 0.7188 | roc auc 0.8636 | pr auc 0.8837 | elapsed 4.04s\n",
      "train epoch 12/15 | batch 437/436 | loss 0.2797 | val loss 0.4651 | acc 0.7855 | f1 0.7727 | prec 0.8217 | recall 0.7292 | roc auc 0.8696 | pr auc 0.8882 | elapsed 3.82s\n",
      "train epoch 13/15 | batch 437/436 | loss 0.2590 | val loss 0.4556 | acc 0.7884 | f1 0.7767 | prec 0.8221 | recall 0.7361 | roc auc 0.8748 | pr auc 0.8921 | elapsed 4.05s\n",
      "train epoch 14/15 | batch 437/436 | loss 0.2408 | val loss 0.4483 | acc 0.7913 | f1 0.7808 | prec 0.8220 | recall 0.7436 | roc auc 0.8791 | pr auc 0.8953 | elapsed 3.95s\n",
      "train epoch 15/15 | batch 437/436 | loss 0.2247 | val loss 0.4421 | acc 0.7933 | f1 0.7842 | prec 0.8203 | recall 0.7512 | roc auc 0.8828 | pr auc 0.8982 | elapsed 4.03s\n",
      "Complexity threshold 6\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 464/463 | loss 0.8944 | val loss 0.9031 | acc 0.6498 | f1 0.5959 | prec 0.7041 | recall 0.5165 | roc auc 0.6935 | pr auc 0.7457 | elapsed 2.07s\n",
      "train epoch 01/15 | batch 464/463 | loss 0.8580 | val loss 0.8284 | acc 0.6630 | f1 0.6136 | prec 0.7192 | recall 0.5350 | roc auc 0.7203 | pr auc 0.7652 | elapsed 4.08s\n",
      "train epoch 02/15 | batch 464/463 | loss 0.7589 | val loss 0.7618 | acc 0.6837 | f1 0.6421 | prec 0.7392 | recall 0.5676 | roc auc 0.7452 | pr auc 0.7842 | elapsed 4.15s\n",
      "train epoch 03/15 | batch 464/463 | loss 0.6705 | val loss 0.7048 | acc 0.7024 | f1 0.6659 | prec 0.7590 | recall 0.5931 | roc auc 0.7678 | pr auc 0.8019 | elapsed 4.26s\n",
      "train epoch 04/15 | batch 464/463 | loss 0.5935 | val loss 0.6562 | acc 0.7176 | f1 0.6860 | prec 0.7724 | recall 0.6169 | roc auc 0.7878 | pr auc 0.8180 | elapsed 4.13s\n",
      "train epoch 05/15 | batch 464/463 | loss 0.5269 | val loss 0.6146 | acc 0.7303 | f1 0.7033 | prec 0.7817 | recall 0.6392 | roc auc 0.8057 | pr auc 0.8327 | elapsed 4.20s\n",
      "train epoch 06/15 | batch 464/463 | loss 0.4698 | val loss 0.5798 | acc 0.7453 | f1 0.7221 | prec 0.7943 | recall 0.6620 | roc auc 0.8210 | pr auc 0.8453 | elapsed 4.33s\n",
      "train epoch 07/15 | batch 464/463 | loss 0.4209 | val loss 0.5502 | acc 0.7534 | f1 0.7334 | prec 0.7982 | recall 0.6782 | roc auc 0.8344 | pr auc 0.8564 | elapsed 4.13s\n",
      "train epoch 08/15 | batch 464/463 | loss 0.3794 | val loss 0.5259 | acc 0.7637 | f1 0.7461 | prec 0.8060 | recall 0.6945 | roc auc 0.8457 | pr auc 0.8659 | elapsed 4.15s\n",
      "train epoch 09/15 | batch 464/463 | loss 0.3440 | val loss 0.5056 | acc 0.7716 | f1 0.7562 | prec 0.8107 | recall 0.7086 | roc auc 0.8552 | pr auc 0.8738 | elapsed 4.43s\n",
      "train epoch 10/15 | batch 464/463 | loss 0.3138 | val loss 0.4888 | acc 0.7792 | f1 0.7650 | prec 0.8174 | recall 0.7189 | roc auc 0.8631 | pr auc 0.8805 | elapsed 4.20s\n",
      "train epoch 11/15 | batch 464/463 | loss 0.2880 | val loss 0.4749 | acc 0.7851 | f1 0.7731 | prec 0.8191 | recall 0.7320 | roc auc 0.8699 | pr auc 0.8861 | elapsed 4.14s\n",
      "train epoch 12/15 | batch 464/463 | loss 0.2657 | val loss 0.4636 | acc 0.7919 | f1 0.7818 | prec 0.8218 | recall 0.7455 | roc auc 0.8755 | pr auc 0.8909 | elapsed 4.51s\n",
      "train epoch 13/15 | batch 464/463 | loss 0.2463 | val loss 0.4543 | acc 0.7938 | f1 0.7851 | prec 0.8198 | recall 0.7531 | roc auc 0.8803 | pr auc 0.8950 | elapsed 4.22s\n",
      "train epoch 14/15 | batch 464/463 | loss 0.2295 | val loss 0.4470 | acc 0.7984 | f1 0.7906 | prec 0.8224 | recall 0.7613 | roc auc 0.8842 | pr auc 0.8984 | elapsed 4.26s\n",
      "train epoch 15/15 | batch 464/463 | loss 0.2146 | val loss 0.4410 | acc 0.8028 | f1 0.7960 | prec 0.8244 | recall 0.7694 | roc auc 0.8877 | pr auc 0.9014 | elapsed 4.00s\n",
      "Complexity threshold 7\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 493/492 | loss 0.9280 | val loss 0.9043 | acc 0.6488 | f1 0.5866 | prec 0.7130 | recall 0.4982 | roc auc 0.6935 | pr auc 0.7442 | elapsed 2.10s\n",
      "train epoch 01/15 | batch 493/492 | loss 0.8850 | val loss 0.8185 | acc 0.6691 | f1 0.6140 | prec 0.7366 | recall 0.5263 | roc auc 0.7245 | pr auc 0.7672 | elapsed 4.34s\n",
      "train epoch 02/15 | batch 493/492 | loss 0.7740 | val loss 0.7421 | acc 0.6936 | f1 0.6466 | prec 0.7638 | recall 0.5606 | roc auc 0.7535 | pr auc 0.7897 | elapsed 4.40s\n",
      "train epoch 03/15 | batch 493/492 | loss 0.6774 | val loss 0.6778 | acc 0.7120 | f1 0.6715 | prec 0.7814 | recall 0.5887 | roc auc 0.7791 | pr auc 0.8102 | elapsed 4.37s\n",
      "train epoch 04/15 | batch 493/492 | loss 0.5926 | val loss 0.6239 | acc 0.7269 | f1 0.6935 | prec 0.7901 | recall 0.6179 | roc auc 0.8018 | pr auc 0.8285 | elapsed 4.75s\n",
      "train epoch 05/15 | batch 493/492 | loss 0.5210 | val loss 0.5792 | acc 0.7453 | f1 0.7180 | prec 0.8041 | recall 0.6486 | roc auc 0.8212 | pr auc 0.8442 | elapsed 4.39s\n",
      "train epoch 06/15 | batch 493/492 | loss 0.4610 | val loss 0.5423 | acc 0.7573 | f1 0.7342 | prec 0.8113 | recall 0.6706 | roc auc 0.8377 | pr auc 0.8578 | elapsed 4.92s\n",
      "train epoch 07/15 | batch 493/492 | loss 0.4107 | val loss 0.5124 | acc 0.7721 | f1 0.7535 | prec 0.8205 | recall 0.6967 | roc auc 0.8513 | pr auc 0.8690 | elapsed 4.41s\n",
      "train epoch 08/15 | batch 493/492 | loss 0.3677 | val loss 0.4883 | acc 0.7824 | f1 0.7664 | prec 0.8270 | recall 0.7141 | roc auc 0.8624 | pr auc 0.8783 | elapsed 4.43s\n",
      "train epoch 09/15 | batch 493/492 | loss 0.3322 | val loss 0.4692 | acc 0.7900 | f1 0.7762 | prec 0.8308 | recall 0.7284 | roc auc 0.8714 | pr auc 0.8859 | elapsed 4.28s\n",
      "train epoch 10/15 | batch 493/492 | loss 0.3016 | val loss 0.4537 | acc 0.7941 | f1 0.7828 | prec 0.8282 | recall 0.7422 | roc auc 0.8790 | pr auc 0.8923 | elapsed 4.41s\n",
      "train epoch 11/15 | batch 493/492 | loss 0.2763 | val loss 0.4419 | acc 0.8028 | f1 0.7935 | prec 0.8330 | recall 0.7575 | roc auc 0.8848 | pr auc 0.8973 | elapsed 4.39s\n",
      "train epoch 12/15 | batch 493/492 | loss 0.2543 | val loss 0.4326 | acc 0.8061 | f1 0.7988 | prec 0.8301 | recall 0.7698 | roc auc 0.8896 | pr auc 0.9014 | elapsed 4.33s\n",
      "train epoch 13/15 | batch 493/492 | loss 0.2357 | val loss 0.4251 | acc 0.8095 | f1 0.8029 | prec 0.8317 | recall 0.7760 | roc auc 0.8936 | pr auc 0.9049 | elapsed 4.41s\n",
      "train epoch 14/15 | batch 493/492 | loss 0.2195 | val loss 0.4195 | acc 0.8133 | f1 0.8081 | prec 0.8313 | recall 0.7862 | roc auc 0.8967 | pr auc 0.9077 | elapsed 4.70s\n",
      "train epoch 15/15 | batch 493/492 | loss 0.2052 | val loss 0.4153 | acc 0.8164 | f1 0.8119 | prec 0.8320 | recall 0.7928 | roc auc 0.8993 | pr auc 0.9099 | elapsed 4.50s\n",
      "Complexity threshold 8\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 522/521 | loss 0.9495 | val loss 0.9555 | acc 0.6356 | f1 0.5664 | prec 0.6990 | recall 0.4761 | roc auc 0.6736 | pr auc 0.7262 | elapsed 2.29s\n",
      "train epoch 01/15 | batch 522/521 | loss 0.9017 | val loss 0.8572 | acc 0.6524 | f1 0.5877 | prec 0.7222 | recall 0.4954 | roc auc 0.7088 | pr auc 0.7522 | elapsed 4.54s\n",
      "train epoch 02/15 | batch 522/521 | loss 0.7806 | val loss 0.7683 | acc 0.6809 | f1 0.6274 | prec 0.7537 | recall 0.5374 | roc auc 0.7421 | pr auc 0.7784 | elapsed 4.77s\n",
      "train epoch 03/15 | batch 522/521 | loss 0.6746 | val loss 0.6937 | acc 0.7033 | f1 0.6600 | prec 0.7728 | recall 0.5760 | roc auc 0.7721 | pr auc 0.8026 | elapsed 4.66s\n",
      "train epoch 04/15 | batch 522/521 | loss 0.5849 | val loss 0.6313 | acc 0.7238 | f1 0.6878 | prec 0.7911 | recall 0.6083 | roc auc 0.7983 | pr auc 0.8240 | elapsed 4.58s\n",
      "train epoch 05/15 | batch 522/521 | loss 0.5096 | val loss 0.5797 | acc 0.7412 | f1 0.7112 | prec 0.8045 | recall 0.6372 | roc auc 0.8209 | pr auc 0.8426 | elapsed 4.62s\n",
      "train epoch 06/15 | batch 522/521 | loss 0.4476 | val loss 0.5376 | acc 0.7574 | f1 0.7326 | prec 0.8159 | recall 0.6647 | roc auc 0.8398 | pr auc 0.8583 | elapsed 4.68s\n",
      "train epoch 07/15 | batch 522/521 | loss 0.3959 | val loss 0.5037 | acc 0.7730 | f1 0.7523 | prec 0.8279 | recall 0.6893 | roc auc 0.8554 | pr auc 0.8713 | elapsed 4.58s\n",
      "train epoch 08/15 | batch 522/521 | loss 0.3538 | val loss 0.4763 | acc 0.7863 | f1 0.7690 | prec 0.8366 | recall 0.7115 | roc auc 0.8683 | pr auc 0.8822 | elapsed 4.49s\n",
      "train epoch 09/15 | batch 522/521 | loss 0.3187 | val loss 0.4546 | acc 0.7923 | f1 0.7778 | prec 0.8363 | recall 0.7270 | roc auc 0.8785 | pr auc 0.8909 | elapsed 4.56s\n",
      "train epoch 10/15 | batch 522/521 | loss 0.2895 | val loss 0.4377 | acc 0.7984 | f1 0.7862 | prec 0.8367 | recall 0.7414 | roc auc 0.8865 | pr auc 0.8977 | elapsed 4.78s\n",
      "train epoch 11/15 | batch 522/521 | loss 0.2651 | val loss 0.4243 | acc 0.8029 | f1 0.7921 | prec 0.8384 | recall 0.7506 | roc auc 0.8928 | pr auc 0.9033 | elapsed 4.59s\n",
      "train epoch 12/15 | batch 522/521 | loss 0.2446 | val loss 0.4139 | acc 0.8097 | f1 0.8006 | prec 0.8408 | recall 0.7641 | roc auc 0.8979 | pr auc 0.9078 | elapsed 4.85s\n",
      "train epoch 13/15 | batch 522/521 | loss 0.2271 | val loss 0.4061 | acc 0.8140 | f1 0.8063 | prec 0.8412 | recall 0.7742 | roc auc 0.9019 | pr auc 0.9114 | elapsed 4.88s\n",
      "train epoch 14/15 | batch 522/521 | loss 0.2118 | val loss 0.4000 | acc 0.8177 | f1 0.8106 | prec 0.8431 | recall 0.7805 | roc auc 0.9051 | pr auc 0.9143 | elapsed 4.51s\n",
      "train epoch 15/15 | batch 522/521 | loss 0.1984 | val loss 0.3957 | acc 0.8222 | f1 0.8159 | prec 0.8461 | recall 0.7877 | roc auc 0.9076 | pr auc 0.9165 | elapsed 4.63s\n",
      "Complexity threshold 9\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 550/549 | loss 0.9864 | val loss 0.9509 | acc 0.6252 | f1 0.5603 | prec 0.6777 | recall 0.4776 | roc auc 0.6780 | pr auc 0.7279 | elapsed 2.58s\n",
      "train epoch 01/15 | batch 550/549 | loss 0.9317 | val loss 0.8405 | acc 0.6527 | f1 0.5960 | prec 0.7123 | recall 0.5124 | roc auc 0.7167 | pr auc 0.7568 | elapsed 4.88s\n",
      "train epoch 02/15 | batch 550/549 | loss 0.7972 | val loss 0.7427 | acc 0.6852 | f1 0.6390 | prec 0.7489 | recall 0.5572 | roc auc 0.7538 | pr auc 0.7863 | elapsed 4.98s\n",
      "train epoch 03/15 | batch 550/549 | loss 0.6797 | val loss 0.6612 | acc 0.7150 | f1 0.6782 | prec 0.7786 | recall 0.6007 | roc auc 0.7869 | pr auc 0.8140 | elapsed 4.92s\n",
      "train epoch 04/15 | batch 550/549 | loss 0.5809 | val loss 0.5954 | acc 0.7402 | f1 0.7116 | prec 0.7995 | recall 0.6410 | roc auc 0.8149 | pr auc 0.8379 | elapsed 4.78s\n",
      "train epoch 05/15 | batch 550/549 | loss 0.5000 | val loss 0.5428 | acc 0.7614 | f1 0.7385 | prec 0.8172 | recall 0.6735 | roc auc 0.8379 | pr auc 0.8581 | elapsed 4.81s\n",
      "train epoch 06/15 | batch 550/549 | loss 0.4350 | val loss 0.5018 | acc 0.7804 | f1 0.7634 | prec 0.8277 | recall 0.7083 | roc auc 0.8563 | pr auc 0.8744 | elapsed 4.89s\n",
      "train epoch 07/15 | batch 550/549 | loss 0.3821 | val loss 0.4700 | acc 0.7967 | f1 0.7828 | prec 0.8403 | recall 0.7326 | roc auc 0.8708 | pr auc 0.8871 | elapsed 4.84s\n",
      "train epoch 08/15 | batch 550/549 | loss 0.3390 | val loss 0.4448 | acc 0.8061 | f1 0.7936 | prec 0.8484 | recall 0.7454 | roc auc 0.8824 | pr auc 0.8974 | elapsed 4.75s\n",
      "train epoch 09/15 | batch 550/549 | loss 0.3045 | val loss 0.4253 | acc 0.8102 | f1 0.7997 | prec 0.8465 | recall 0.7578 | roc auc 0.8915 | pr auc 0.9053 | elapsed 5.25s\n",
      "train epoch 10/15 | batch 550/549 | loss 0.2764 | val loss 0.4101 | acc 0.8164 | f1 0.8071 | prec 0.8501 | recall 0.7683 | roc auc 0.8985 | pr auc 0.9116 | elapsed 4.85s\n",
      "train epoch 11/15 | batch 550/549 | loss 0.2530 | val loss 0.3982 | acc 0.8253 | f1 0.8170 | prec 0.8579 | recall 0.7798 | roc auc 0.9041 | pr auc 0.9165 | elapsed 4.96s\n",
      "train epoch 12/15 | batch 550/549 | loss 0.2335 | val loss 0.3891 | acc 0.8288 | f1 0.8216 | prec 0.8572 | recall 0.7889 | roc auc 0.9084 | pr auc 0.9203 | elapsed 4.69s\n",
      "train epoch 13/15 | batch 550/549 | loss 0.2167 | val loss 0.3819 | acc 0.8349 | f1 0.8288 | prec 0.8609 | recall 0.7990 | roc auc 0.9118 | pr auc 0.9232 | elapsed 4.64s\n",
      "train epoch 14/15 | batch 550/549 | loss 0.2027 | val loss 0.3764 | acc 0.8391 | f1 0.8337 | prec 0.8625 | recall 0.8068 | roc auc 0.9145 | pr auc 0.9255 | elapsed 4.60s\n",
      "train epoch 15/15 | batch 550/549 | loss 0.1898 | val loss 0.3720 | acc 0.8409 | f1 0.8357 | prec 0.8637 | recall 0.8095 | roc auc 0.9168 | pr auc 0.9275 | elapsed 4.70s\n",
      "Complexity threshold 10\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 577/576 | loss 0.9925 | val loss 0.9775 | acc 0.6272 | f1 0.5585 | prec 0.6846 | recall 0.4716 | roc auc 0.6660 | pr auc 0.7197 | elapsed 2.42s\n",
      "train epoch 01/15 | batch 577/576 | loss 0.9293 | val loss 0.8548 | acc 0.6521 | f1 0.5911 | prec 0.7166 | recall 0.5031 | roc auc 0.7086 | pr auc 0.7519 | elapsed 4.89s\n",
      "train epoch 02/15 | batch 577/576 | loss 0.7844 | val loss 0.7489 | acc 0.6832 | f1 0.6335 | prec 0.7515 | recall 0.5476 | roc auc 0.7483 | pr auc 0.7834 | elapsed 4.91s\n",
      "train epoch 03/15 | batch 577/576 | loss 0.6605 | val loss 0.6617 | acc 0.7077 | f1 0.6691 | prec 0.7708 | recall 0.5912 | roc auc 0.7838 | pr auc 0.8128 | elapsed 4.86s\n",
      "train epoch 04/15 | batch 577/576 | loss 0.5587 | val loss 0.5913 | acc 0.7310 | f1 0.7005 | prec 0.7901 | recall 0.6291 | roc auc 0.8141 | pr auc 0.8383 | elapsed 4.90s\n",
      "train epoch 05/15 | batch 577/576 | loss 0.4773 | val loss 0.5358 | acc 0.7552 | f1 0.7330 | prec 0.8063 | recall 0.6719 | roc auc 0.8389 | pr auc 0.8596 | elapsed 4.84s\n",
      "train epoch 06/15 | batch 577/576 | loss 0.4130 | val loss 0.4923 | acc 0.7740 | f1 0.7565 | prec 0.8201 | recall 0.7020 | roc auc 0.8587 | pr auc 0.8766 | elapsed 4.83s\n",
      "train epoch 07/15 | batch 577/576 | loss 0.3624 | val loss 0.4587 | acc 0.7925 | f1 0.7797 | prec 0.8311 | recall 0.7343 | roc auc 0.8744 | pr auc 0.8901 | elapsed 4.95s\n",
      "train epoch 08/15 | batch 577/576 | loss 0.3223 | val loss 0.4323 | acc 0.8052 | f1 0.7948 | prec 0.8397 | recall 0.7544 | roc auc 0.8868 | pr auc 0.9008 | elapsed 5.05s\n",
      "train epoch 09/15 | batch 577/576 | loss 0.2902 | val loss 0.4118 | acc 0.8124 | f1 0.8032 | prec 0.8446 | recall 0.7657 | roc auc 0.8964 | pr auc 0.9092 | elapsed 4.94s\n",
      "train epoch 10/15 | batch 577/576 | loss 0.2641 | val loss 0.3963 | acc 0.8233 | f1 0.8162 | prec 0.8505 | recall 0.7845 | roc auc 0.9037 | pr auc 0.9155 | elapsed 4.95s\n",
      "train epoch 11/15 | batch 577/576 | loss 0.2424 | val loss 0.3839 | acc 0.8305 | f1 0.8254 | prec 0.8512 | recall 0.8010 | roc auc 0.9096 | pr auc 0.9207 | elapsed 5.00s\n",
      "train epoch 12/15 | batch 577/576 | loss 0.2243 | val loss 0.3743 | acc 0.8344 | f1 0.8300 | prec 0.8527 | recall 0.8085 | roc auc 0.9141 | pr auc 0.9247 | elapsed 4.96s\n",
      "train epoch 13/15 | batch 577/576 | loss 0.2088 | val loss 0.3671 | acc 0.8364 | f1 0.8326 | prec 0.8524 | recall 0.8137 | roc auc 0.9176 | pr auc 0.9278 | elapsed 4.97s\n",
      "train epoch 14/15 | batch 577/576 | loss 0.1954 | val loss 0.3615 | acc 0.8403 | f1 0.8372 | prec 0.8539 | recall 0.8211 | roc auc 0.9205 | pr auc 0.9303 | elapsed 4.91s\n",
      "train epoch 15/15 | batch 577/576 | loss 0.1835 | val loss 0.3572 | acc 0.8438 | f1 0.8412 | prec 0.8556 | recall 0.8272 | roc auc 0.9227 | pr auc 0.9322 | elapsed 4.93s\n",
      "Complexity threshold 11\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 609/608 | loss 1.0242 | val loss 1.0332 | acc 0.6148 | f1 0.5388 | prec 0.6712 | recall 0.4500 | roc auc 0.6424 | pr auc 0.7037 | elapsed 2.58s\n",
      "train epoch 01/15 | batch 609/608 | loss 0.9551 | val loss 0.8914 | acc 0.6420 | f1 0.5775 | prec 0.7045 | recall 0.4893 | roc auc 0.6916 | pr auc 0.7392 | elapsed 5.18s\n",
      "train epoch 02/15 | batch 609/608 | loss 0.7971 | val loss 0.7673 | acc 0.6777 | f1 0.6270 | prec 0.7442 | recall 0.5417 | roc auc 0.7391 | pr auc 0.7755 | elapsed 5.32s\n",
      "train epoch 03/15 | batch 609/608 | loss 0.6623 | val loss 0.6660 | acc 0.7081 | f1 0.6705 | prec 0.7695 | recall 0.5941 | roc auc 0.7814 | pr auc 0.8097 | elapsed 5.19s\n",
      "train epoch 04/15 | batch 609/608 | loss 0.5536 | val loss 0.5864 | acc 0.7405 | f1 0.7131 | prec 0.7973 | recall 0.6449 | roc auc 0.8166 | pr auc 0.8393 | elapsed 5.26s\n",
      "train epoch 05/15 | batch 609/608 | loss 0.4685 | val loss 0.5255 | acc 0.7673 | f1 0.7478 | prec 0.8163 | recall 0.6899 | roc auc 0.8441 | pr auc 0.8632 | elapsed 5.19s\n",
      "train epoch 06/15 | batch 609/608 | loss 0.4030 | val loss 0.4801 | acc 0.7900 | f1 0.7759 | prec 0.8318 | recall 0.7271 | roc auc 0.8649 | pr auc 0.8813 | elapsed 5.16s\n",
      "train epoch 07/15 | batch 609/608 | loss 0.3523 | val loss 0.4454 | acc 0.8062 | f1 0.7960 | prec 0.8400 | recall 0.7564 | roc auc 0.8809 | pr auc 0.8950 | elapsed 5.65s\n",
      "train epoch 08/15 | batch 609/608 | loss 0.3125 | val loss 0.4188 | acc 0.8159 | f1 0.8081 | prec 0.8437 | recall 0.7754 | roc auc 0.8931 | pr auc 0.9055 | elapsed 5.16s\n",
      "train epoch 09/15 | batch 609/608 | loss 0.2808 | val loss 0.3987 | acc 0.8260 | f1 0.8198 | prec 0.8498 | recall 0.7919 | roc auc 0.9026 | pr auc 0.9135 | elapsed 5.19s\n",
      "train epoch 10/15 | batch 609/608 | loss 0.2552 | val loss 0.3829 | acc 0.8326 | f1 0.8274 | prec 0.8538 | recall 0.8026 | roc auc 0.9100 | pr auc 0.9196 | elapsed 5.16s\n",
      "train epoch 11/15 | batch 609/608 | loss 0.2340 | val loss 0.3706 | acc 0.8371 | f1 0.8326 | prec 0.8564 | recall 0.8101 | roc auc 0.9158 | pr auc 0.9245 | elapsed 5.17s\n",
      "train epoch 12/15 | batch 609/608 | loss 0.2163 | val loss 0.3612 | acc 0.8402 | f1 0.8363 | prec 0.8573 | recall 0.8163 | roc auc 0.9202 | pr auc 0.9283 | elapsed 5.21s\n",
      "train epoch 13/15 | batch 609/608 | loss 0.2011 | val loss 0.3539 | acc 0.8437 | f1 0.8404 | prec 0.8587 | recall 0.8229 | roc auc 0.9237 | pr auc 0.9313 | elapsed 5.24s\n",
      "train epoch 14/15 | batch 609/608 | loss 0.1880 | val loss 0.3483 | acc 0.8476 | f1 0.8448 | prec 0.8608 | recall 0.8295 | roc auc 0.9266 | pr auc 0.9338 | elapsed 5.15s\n",
      "train epoch 15/15 | batch 609/608 | loss 0.1763 | val loss 0.3442 | acc 0.8501 | f1 0.8480 | prec 0.8602 | recall 0.8361 | roc auc 0.9287 | pr auc 0.9357 | elapsed 5.15s\n",
      "Complexity threshold 12\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 641/640 | loss 1.0479 | val loss 1.0616 | acc 0.5998 | f1 0.5099 | prec 0.6580 | recall 0.4162 | roc auc 0.6301 | pr auc 0.6881 | elapsed 2.77s\n",
      "train epoch 01/15 | batch 641/640 | loss 0.9681 | val loss 0.9031 | acc 0.6333 | f1 0.5583 | prec 0.7024 | recall 0.4633 | roc auc 0.6849 | pr auc 0.7290 | elapsed 5.40s\n",
      "train epoch 02/15 | batch 641/640 | loss 0.7946 | val loss 0.7664 | acc 0.6738 | f1 0.6191 | prec 0.7442 | recall 0.5300 | roc auc 0.7374 | pr auc 0.7710 | elapsed 5.39s\n",
      "train epoch 03/15 | batch 641/640 | loss 0.6577 | val loss 0.6562 | acc 0.7092 | f1 0.6698 | prec 0.7750 | recall 0.5897 | roc auc 0.7840 | pr auc 0.8101 | elapsed 5.46s\n",
      "train epoch 04/15 | batch 641/640 | loss 0.5425 | val loss 0.5720 | acc 0.7410 | f1 0.7134 | prec 0.7986 | recall 0.6447 | roc auc 0.8216 | pr auc 0.8425 | elapsed 5.37s\n",
      "train epoch 05/15 | batch 641/640 | loss 0.4570 | val loss 0.5091 | acc 0.7677 | f1 0.7482 | prec 0.8169 | recall 0.6902 | roc auc 0.8507 | pr auc 0.8680 | elapsed 5.47s\n",
      "train epoch 06/15 | batch 641/640 | loss 0.3914 | val loss 0.4623 | acc 0.7901 | f1 0.7761 | prec 0.8317 | recall 0.7275 | roc auc 0.8727 | pr auc 0.8872 | elapsed 5.43s\n",
      "train epoch 07/15 | batch 641/640 | loss 0.3414 | val loss 0.4275 | acc 0.8044 | f1 0.7945 | prec 0.8373 | recall 0.7558 | roc auc 0.8891 | pr auc 0.9016 | elapsed 5.41s\n",
      "train epoch 08/15 | batch 641/640 | loss 0.3041 | val loss 0.4015 | acc 0.8174 | f1 0.8101 | prec 0.8439 | recall 0.7790 | roc auc 0.9013 | pr auc 0.9123 | elapsed 5.42s\n",
      "train epoch 09/15 | batch 641/640 | loss 0.2730 | val loss 0.3820 | acc 0.8260 | f1 0.8206 | prec 0.8473 | recall 0.7954 | roc auc 0.9102 | pr auc 0.9203 | elapsed 5.42s\n",
      "train epoch 10/15 | batch 641/640 | loss 0.2470 | val loss 0.3676 | acc 0.8344 | f1 0.8303 | prec 0.8518 | recall 0.8100 | roc auc 0.9169 | pr auc 0.9262 | elapsed 5.48s\n",
      "train epoch 11/15 | batch 641/640 | loss 0.2267 | val loss 0.3568 | acc 0.8405 | f1 0.8371 | prec 0.8557 | recall 0.8194 | roc auc 0.9218 | pr auc 0.9307 | elapsed 5.42s\n",
      "train epoch 12/15 | batch 641/640 | loss 0.2102 | val loss 0.3486 | acc 0.8451 | f1 0.8424 | prec 0.8576 | recall 0.8276 | roc auc 0.9256 | pr auc 0.9341 | elapsed 5.37s\n",
      "train epoch 13/15 | batch 641/640 | loss 0.1955 | val loss 0.3423 | acc 0.8509 | f1 0.8492 | prec 0.8596 | recall 0.8390 | roc auc 0.9285 | pr auc 0.9368 | elapsed 5.47s\n",
      "train epoch 14/15 | batch 641/640 | loss 0.1836 | val loss 0.3376 | acc 0.8541 | f1 0.8528 | prec 0.8605 | recall 0.8453 | roc auc 0.9309 | pr auc 0.9389 | elapsed 5.50s\n",
      "train epoch 15/15 | batch 641/640 | loss 0.1720 | val loss 0.3341 | acc 0.8572 | f1 0.8562 | prec 0.8628 | recall 0.8496 | roc auc 0.9327 | pr auc 0.9405 | elapsed 5.38s\n",
      "Complexity threshold 13\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 680/679 | loss 1.0656 | val loss 1.0667 | acc 0.5974 | f1 0.5042 | prec 0.6574 | recall 0.4089 | roc auc 0.6281 | pr auc 0.6839 | elapsed 2.85s\n",
      "train epoch 01/15 | batch 680/679 | loss 0.9809 | val loss 0.8915 | acc 0.6365 | f1 0.5592 | prec 0.7114 | recall 0.4607 | roc auc 0.6901 | pr auc 0.7307 | elapsed 5.76s\n",
      "train epoch 02/15 | batch 680/679 | loss 0.7961 | val loss 0.7418 | acc 0.6851 | f1 0.6318 | prec 0.7617 | recall 0.5397 | roc auc 0.7490 | pr auc 0.7787 | elapsed 5.74s\n",
      "train epoch 03/15 | batch 680/679 | loss 0.6420 | val loss 0.6235 | acc 0.7254 | f1 0.6884 | prec 0.7969 | recall 0.6058 | roc auc 0.7999 | pr auc 0.8228 | elapsed 5.74s\n",
      "train epoch 04/15 | batch 680/679 | loss 0.5220 | val loss 0.5363 | acc 0.7633 | f1 0.7382 | prec 0.8268 | recall 0.6668 | roc auc 0.8393 | pr auc 0.8578 | elapsed 5.76s\n",
      "train epoch 05/15 | batch 680/679 | loss 0.4334 | val loss 0.4734 | acc 0.7925 | f1 0.7760 | prec 0.8441 | recall 0.7181 | roc auc 0.8681 | pr auc 0.8839 | elapsed 5.85s\n",
      "train epoch 06/15 | batch 680/679 | loss 0.3680 | val loss 0.4285 | acc 0.8129 | f1 0.8008 | prec 0.8571 | recall 0.7514 | roc auc 0.8885 | pr auc 0.9023 | elapsed 5.85s\n",
      "train epoch 07/15 | batch 680/679 | loss 0.3190 | val loss 0.3964 | acc 0.8271 | f1 0.8183 | prec 0.8634 | recall 0.7776 | roc auc 0.9031 | pr auc 0.9153 | elapsed 5.81s\n",
      "train epoch 08/15 | batch 680/679 | loss 0.2819 | val loss 0.3735 | acc 0.8369 | f1 0.8299 | prec 0.8684 | recall 0.7946 | roc auc 0.9134 | pr auc 0.9244 | elapsed 5.87s\n",
      "train epoch 09/15 | batch 680/679 | loss 0.2531 | val loss 0.3567 | acc 0.8441 | f1 0.8388 | prec 0.8695 | recall 0.8101 | roc auc 0.9209 | pr auc 0.9311 | elapsed 6.03s\n",
      "train epoch 10/15 | batch 680/679 | loss 0.2301 | val loss 0.3446 | acc 0.8506 | f1 0.8465 | prec 0.8713 | recall 0.8231 | roc auc 0.9262 | pr auc 0.9358 | elapsed 5.82s\n",
      "train epoch 11/15 | batch 680/679 | loss 0.2109 | val loss 0.3357 | acc 0.8560 | f1 0.8527 | prec 0.8734 | recall 0.8330 | roc auc 0.9301 | pr auc 0.9393 | elapsed 5.81s\n",
      "train epoch 12/15 | batch 680/679 | loss 0.1951 | val loss 0.3294 | acc 0.8576 | f1 0.8549 | prec 0.8724 | recall 0.8382 | roc auc 0.9329 | pr auc 0.9418 | elapsed 5.80s\n",
      "train epoch 13/15 | batch 680/679 | loss 0.1818 | val loss 0.3252 | acc 0.8602 | f1 0.8580 | prec 0.8728 | recall 0.8437 | roc auc 0.9350 | pr auc 0.9436 | elapsed 5.99s\n",
      "train epoch 14/15 | batch 680/679 | loss 0.1702 | val loss 0.3220 | acc 0.8622 | f1 0.8603 | prec 0.8736 | recall 0.8474 | roc auc 0.9367 | pr auc 0.9451 | elapsed 5.75s\n",
      "train epoch 15/15 | batch 680/679 | loss 0.1599 | val loss 0.3198 | acc 0.8648 | f1 0.8631 | prec 0.8751 | recall 0.8515 | roc auc 0.9380 | pr auc 0.9462 | elapsed 5.78s\n",
      "Complexity threshold 14\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 712/711 | loss 1.0916 | val loss 1.1037 | acc 0.5913 | f1 0.4958 | prec 0.6552 | recall 0.3987 | roc auc 0.6174 | pr auc 0.6773 | elapsed 3.29s\n",
      "train epoch 01/15 | batch 712/711 | loss 0.9997 | val loss 0.9148 | acc 0.6285 | f1 0.5529 | prec 0.7025 | recall 0.4559 | roc auc 0.6831 | pr auc 0.7258 | elapsed 6.77s\n",
      "train epoch 02/15 | batch 712/711 | loss 0.7997 | val loss 0.7517 | acc 0.6748 | f1 0.6221 | prec 0.7505 | recall 0.5312 | roc auc 0.7466 | pr auc 0.7765 | elapsed 6.71s\n",
      "train epoch 03/15 | batch 712/711 | loss 0.6353 | val loss 0.6250 | acc 0.7203 | f1 0.6868 | prec 0.7881 | recall 0.6086 | roc auc 0.8006 | pr auc 0.8228 | elapsed 6.68s\n",
      "train epoch 04/15 | batch 712/711 | loss 0.5107 | val loss 0.5333 | acc 0.7576 | f1 0.7374 | prec 0.8118 | recall 0.6755 | roc auc 0.8416 | pr auc 0.8596 | elapsed 6.41s\n",
      "train epoch 05/15 | batch 712/711 | loss 0.4211 | val loss 0.4689 | acc 0.7924 | f1 0.7806 | prec 0.8348 | recall 0.7330 | roc auc 0.8707 | pr auc 0.8861 | elapsed 6.37s\n",
      "train epoch 06/15 | batch 712/711 | loss 0.3568 | val loss 0.4238 | acc 0.8146 | f1 0.8066 | prec 0.8502 | recall 0.7673 | roc auc 0.8914 | pr auc 0.9045 | elapsed 6.41s\n",
      "train epoch 07/15 | batch 712/711 | loss 0.3095 | val loss 0.3916 | acc 0.8286 | f1 0.8230 | prec 0.8576 | recall 0.7912 | roc auc 0.9060 | pr auc 0.9175 | elapsed 6.23s\n",
      "train epoch 08/15 | batch 712/711 | loss 0.2739 | val loss 0.3682 | acc 0.8370 | f1 0.8338 | prec 0.8577 | recall 0.8111 | roc auc 0.9165 | pr auc 0.9268 | elapsed 6.56s\n",
      "train epoch 09/15 | batch 712/711 | loss 0.2465 | val loss 0.3511 | acc 0.8448 | f1 0.8428 | prec 0.8608 | recall 0.8255 | roc auc 0.9240 | pr auc 0.9336 | elapsed 6.56s\n",
      "train epoch 10/15 | batch 712/711 | loss 0.2249 | val loss 0.3384 | acc 0.8510 | f1 0.8496 | prec 0.8644 | recall 0.8353 | roc auc 0.9295 | pr auc 0.9386 | elapsed 6.36s\n",
      "train epoch 11/15 | batch 712/711 | loss 0.2071 | val loss 0.3287 | acc 0.8547 | f1 0.8541 | prec 0.8644 | recall 0.8441 | roc auc 0.9336 | pr auc 0.9425 | elapsed 6.34s\n",
      "train epoch 12/15 | batch 712/711 | loss 0.1923 | val loss 0.3217 | acc 0.8577 | f1 0.8576 | prec 0.8649 | recall 0.8504 | roc auc 0.9367 | pr auc 0.9453 | elapsed 7.35s\n",
      "train epoch 13/15 | batch 712/711 | loss 0.1796 | val loss 0.3160 | acc 0.8607 | f1 0.8610 | prec 0.8657 | recall 0.8563 | roc auc 0.9392 | pr auc 0.9477 | elapsed 6.47s\n",
      "train epoch 14/15 | batch 712/711 | loss 0.1685 | val loss 0.3116 | acc 0.8632 | f1 0.8637 | prec 0.8672 | recall 0.8602 | roc auc 0.9412 | pr auc 0.9495 | elapsed 6.41s\n",
      "train epoch 15/15 | batch 712/711 | loss 0.1587 | val loss 0.3083 | acc 0.8669 | f1 0.8675 | prec 0.8700 | recall 0.8651 | roc auc 0.9427 | pr auc 0.9510 | elapsed 6.20s\n",
      "Complexity threshold 15\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 744/743 | loss 1.1281 | val loss 1.0992 | acc 0.5892 | f1 0.4981 | prec 0.6636 | recall 0.3987 | roc auc 0.6211 | pr auc 0.6857 | elapsed 3.77s\n",
      "train epoch 01/15 | batch 744/743 | loss 1.0223 | val loss 0.8971 | acc 0.6361 | f1 0.5721 | prec 0.7175 | recall 0.4757 | roc auc 0.6920 | pr auc 0.7396 | elapsed 6.62s\n",
      "train epoch 02/15 | batch 744/743 | loss 0.7979 | val loss 0.7280 | acc 0.6885 | f1 0.6474 | prec 0.7685 | recall 0.5593 | roc auc 0.7581 | pr auc 0.7940 | elapsed 6.34s\n",
      "train epoch 03/15 | batch 744/743 | loss 0.6195 | val loss 0.6020 | acc 0.7361 | f1 0.7129 | prec 0.8036 | recall 0.6406 | roc auc 0.8120 | pr auc 0.8405 | elapsed 6.57s\n",
      "train epoch 04/15 | batch 744/743 | loss 0.4901 | val loss 0.5150 | acc 0.7757 | f1 0.7623 | prec 0.8317 | recall 0.7037 | roc auc 0.8507 | pr auc 0.8743 | elapsed 6.54s\n",
      "train epoch 05/15 | batch 744/743 | loss 0.4016 | val loss 0.4557 | acc 0.8000 | f1 0.7921 | prec 0.8455 | recall 0.7450 | roc auc 0.8775 | pr auc 0.8974 | elapsed 6.87s\n",
      "train epoch 06/15 | batch 744/743 | loss 0.3390 | val loss 0.4140 | acc 0.8169 | f1 0.8123 | prec 0.8537 | recall 0.7747 | roc auc 0.8964 | pr auc 0.9133 | elapsed 7.00s\n",
      "train epoch 07/15 | batch 744/743 | loss 0.2942 | val loss 0.3845 | acc 0.8302 | f1 0.8275 | prec 0.8611 | recall 0.7965 | roc auc 0.9096 | pr auc 0.9243 | elapsed 6.61s\n",
      "train epoch 08/15 | batch 744/743 | loss 0.2602 | val loss 0.3631 | acc 0.8395 | f1 0.8379 | prec 0.8666 | recall 0.8110 | roc auc 0.9192 | pr auc 0.9320 | elapsed 6.46s\n",
      "train epoch 09/15 | batch 744/743 | loss 0.2342 | val loss 0.3473 | acc 0.8498 | f1 0.8493 | prec 0.8722 | recall 0.8276 | roc auc 0.9262 | pr auc 0.9378 | elapsed 6.39s\n",
      "train epoch 10/15 | batch 744/743 | loss 0.2135 | val loss 0.3356 | acc 0.8561 | f1 0.8561 | prec 0.8759 | recall 0.8371 | roc auc 0.9315 | pr auc 0.9420 | elapsed 6.40s\n",
      "train epoch 11/15 | batch 744/743 | loss 0.1966 | val loss 0.3271 | acc 0.8581 | f1 0.8587 | prec 0.8746 | recall 0.8434 | roc auc 0.9353 | pr auc 0.9451 | elapsed 6.42s\n",
      "train epoch 12/15 | batch 744/743 | loss 0.1823 | val loss 0.3205 | acc 0.8613 | f1 0.8622 | prec 0.8765 | recall 0.8484 | roc auc 0.9383 | pr auc 0.9475 | elapsed 6.48s\n",
      "train epoch 13/15 | batch 744/743 | loss 0.1702 | val loss 0.3156 | acc 0.8649 | f1 0.8660 | prec 0.8786 | recall 0.8537 | roc auc 0.9407 | pr auc 0.9494 | elapsed 6.94s\n",
      "train epoch 14/15 | batch 744/743 | loss 0.1596 | val loss 0.3121 | acc 0.8654 | f1 0.8666 | prec 0.8782 | recall 0.8553 | roc auc 0.9424 | pr auc 0.9508 | elapsed 6.52s\n",
      "train epoch 15/15 | batch 744/743 | loss 0.1500 | val loss 0.3093 | acc 0.8666 | f1 0.8680 | prec 0.8780 | recall 0.8583 | roc auc 0.9439 | pr auc 0.9520 | elapsed 6.69s\n",
      "Complexity threshold 16\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 773/772 | loss 1.1517 | val loss 1.1292 | acc 0.5889 | f1 0.4951 | prec 0.6817 | recall 0.3887 | roc auc 0.6136 | pr auc 0.6830 | elapsed 3.50s\n",
      "train epoch 01/15 | batch 773/772 | loss 1.0392 | val loss 0.9010 | acc 0.6361 | f1 0.5663 | prec 0.7410 | recall 0.4583 | roc auc 0.6937 | pr auc 0.7430 | elapsed 7.08s\n",
      "train epoch 02/15 | batch 773/772 | loss 0.8014 | val loss 0.7077 | acc 0.6920 | f1 0.6507 | prec 0.7897 | recall 0.5533 | roc auc 0.7709 | pr auc 0.8042 | elapsed 7.03s\n",
      "train epoch 03/15 | batch 773/772 | loss 0.6139 | val loss 0.5688 | acc 0.7508 | f1 0.7316 | prec 0.8286 | recall 0.6549 | roc auc 0.8309 | pr auc 0.8555 | elapsed 6.98s\n",
      "train epoch 04/15 | batch 773/772 | loss 0.4811 | val loss 0.4772 | acc 0.7999 | f1 0.7929 | prec 0.8558 | recall 0.7386 | roc auc 0.8710 | pr auc 0.8906 | elapsed 7.06s\n",
      "train epoch 05/15 | batch 773/772 | loss 0.3914 | val loss 0.4178 | acc 0.8235 | f1 0.8203 | prec 0.8689 | recall 0.7768 | roc auc 0.8966 | pr auc 0.9130 | elapsed 6.71s\n",
      "train epoch 06/15 | batch 773/772 | loss 0.3297 | val loss 0.3779 | acc 0.8443 | f1 0.8441 | prec 0.8775 | recall 0.8132 | roc auc 0.9133 | pr auc 0.9273 | elapsed 7.25s\n",
      "train epoch 07/15 | batch 773/772 | loss 0.2854 | val loss 0.3504 | acc 0.8570 | f1 0.8578 | prec 0.8850 | recall 0.8323 | roc auc 0.9245 | pr auc 0.9369 | elapsed 7.25s\n",
      "train epoch 08/15 | batch 773/772 | loss 0.2526 | val loss 0.3311 | acc 0.8635 | f1 0.8652 | prec 0.8863 | recall 0.8451 | roc auc 0.9324 | pr auc 0.9434 | elapsed 7.01s\n",
      "train epoch 09/15 | batch 773/772 | loss 0.2273 | val loss 0.3169 | acc 0.8691 | f1 0.8713 | prec 0.8891 | recall 0.8542 | roc auc 0.9383 | pr auc 0.9482 | elapsed 6.99s\n",
      "train epoch 10/15 | batch 773/772 | loss 0.2072 | val loss 0.3064 | acc 0.8709 | f1 0.8734 | prec 0.8885 | recall 0.8589 | roc auc 0.9427 | pr auc 0.9518 | elapsed 7.22s\n",
      "train epoch 11/15 | batch 773/772 | loss 0.1908 | val loss 0.2987 | acc 0.8753 | f1 0.8781 | prec 0.8907 | recall 0.8658 | roc auc 0.9459 | pr auc 0.9545 | elapsed 7.23s\n",
      "train epoch 12/15 | batch 773/772 | loss 0.1770 | val loss 0.2929 | acc 0.8784 | f1 0.8814 | prec 0.8916 | recall 0.8715 | roc auc 0.9483 | pr auc 0.9565 | elapsed 6.82s\n",
      "train epoch 13/15 | batch 773/772 | loss 0.1651 | val loss 0.2885 | acc 0.8781 | f1 0.8811 | prec 0.8910 | recall 0.8715 | roc auc 0.9501 | pr auc 0.9580 | elapsed 7.38s\n",
      "train epoch 14/15 | batch 773/772 | loss 0.1548 | val loss 0.2852 | acc 0.8792 | f1 0.8825 | prec 0.8903 | recall 0.8749 | roc auc 0.9516 | pr auc 0.9592 | elapsed 7.52s\n",
      "train epoch 15/15 | batch 773/772 | loss 0.1456 | val loss 0.2827 | acc 0.8810 | f1 0.8843 | prec 0.8919 | recall 0.8768 | roc auc 0.9527 | pr auc 0.9603 | elapsed 7.20s\n",
      "Complexity threshold 17\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 808/807 | loss 1.1937 | val loss 1.1920 | acc 0.5705 | f1 0.4730 | prec 0.6676 | recall 0.3663 | roc auc 0.5954 | pr auc 0.6735 | elapsed 3.61s\n",
      "train epoch 01/15 | batch 808/807 | loss 1.0638 | val loss 0.9372 | acc 0.6213 | f1 0.5518 | prec 0.7315 | recall 0.4430 | roc auc 0.6815 | pr auc 0.7372 | elapsed 7.25s\n",
      "train epoch 02/15 | batch 808/807 | loss 0.7988 | val loss 0.7245 | acc 0.6846 | f1 0.6462 | prec 0.7889 | recall 0.5472 | roc auc 0.7637 | pr auc 0.8030 | elapsed 7.10s\n",
      "train epoch 03/15 | batch 808/807 | loss 0.5962 | val loss 0.5755 | acc 0.7499 | f1 0.7341 | prec 0.8332 | recall 0.6561 | roc auc 0.8270 | pr auc 0.8572 | elapsed 7.41s\n",
      "train epoch 04/15 | batch 808/807 | loss 0.4609 | val loss 0.4816 | acc 0.7946 | f1 0.7891 | prec 0.8587 | recall 0.7299 | roc auc 0.8679 | pr auc 0.8929 | elapsed 7.02s\n",
      "train epoch 05/15 | batch 808/807 | loss 0.3732 | val loss 0.4221 | acc 0.8204 | f1 0.8194 | prec 0.8703 | recall 0.7742 | roc auc 0.8936 | pr auc 0.9147 | elapsed 7.60s\n",
      "train epoch 06/15 | batch 808/807 | loss 0.3142 | val loss 0.3823 | acc 0.8359 | f1 0.8369 | prec 0.8778 | recall 0.7996 | roc auc 0.9108 | pr auc 0.9287 | elapsed 7.23s\n",
      "train epoch 07/15 | batch 808/807 | loss 0.2719 | val loss 0.3548 | acc 0.8499 | f1 0.8521 | prec 0.8852 | recall 0.8214 | roc auc 0.9224 | pr auc 0.9381 | elapsed 7.19s\n",
      "train epoch 08/15 | batch 808/807 | loss 0.2405 | val loss 0.3354 | acc 0.8585 | f1 0.8613 | prec 0.8893 | recall 0.8350 | roc auc 0.9305 | pr auc 0.9445 | elapsed 7.67s\n",
      "train epoch 09/15 | batch 808/807 | loss 0.2165 | val loss 0.3214 | acc 0.8667 | f1 0.8701 | prec 0.8933 | recall 0.8480 | roc auc 0.9362 | pr auc 0.9490 | elapsed 6.95s\n",
      "train epoch 10/15 | batch 808/807 | loss 0.1974 | val loss 0.3112 | acc 0.8714 | f1 0.8753 | prec 0.8936 | recall 0.8577 | roc auc 0.9402 | pr auc 0.9523 | elapsed 7.02s\n",
      "train epoch 11/15 | batch 808/807 | loss 0.1817 | val loss 0.3037 | acc 0.8725 | f1 0.8768 | prec 0.8917 | recall 0.8625 | roc auc 0.9431 | pr auc 0.9547 | elapsed 6.86s\n",
      "train epoch 12/15 | batch 808/807 | loss 0.1684 | val loss 0.2982 | acc 0.8728 | f1 0.8776 | prec 0.8891 | recall 0.8663 | roc auc 0.9454 | pr auc 0.9566 | elapsed 7.09s\n",
      "train epoch 13/15 | batch 808/807 | loss 0.1570 | val loss 0.2941 | acc 0.8745 | f1 0.8793 | prec 0.8900 | recall 0.8689 | roc auc 0.9472 | pr auc 0.9580 | elapsed 7.47s\n",
      "train epoch 14/15 | batch 808/807 | loss 0.1472 | val loss 0.2913 | acc 0.8762 | f1 0.8812 | prec 0.8903 | recall 0.8722 | roc auc 0.9486 | pr auc 0.9591 | elapsed 6.78s\n",
      "train epoch 15/15 | batch 808/807 | loss 0.1383 | val loss 0.2891 | acc 0.8771 | f1 0.8822 | prec 0.8903 | recall 0.8743 | roc auc 0.9497 | pr auc 0.9600 | elapsed 7.14s\n",
      "Complexity threshold 18\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 829/828 | loss 1.2009 | val loss 1.2202 | acc 0.5548 | f1 0.4655 | prec 0.6411 | recall 0.3654 | roc auc 0.5775 | pr auc 0.6645 | elapsed 3.52s\n",
      "train epoch 01/15 | batch 829/828 | loss 1.0680 | val loss 0.9508 | acc 0.6095 | f1 0.5482 | prec 0.7098 | recall 0.4466 | roc auc 0.6681 | pr auc 0.7309 | elapsed 7.05s\n",
      "train epoch 02/15 | batch 829/828 | loss 0.7937 | val loss 0.7267 | acc 0.6817 | f1 0.6540 | prec 0.7724 | recall 0.5671 | roc auc 0.7565 | pr auc 0.8019 | elapsed 7.05s\n",
      "train epoch 03/15 | batch 829/828 | loss 0.5868 | val loss 0.5738 | acc 0.7455 | f1 0.7356 | prec 0.8194 | recall 0.6674 | roc auc 0.8238 | pr auc 0.8588 | elapsed 6.99s\n",
      "train epoch 04/15 | batch 829/828 | loss 0.4525 | val loss 0.4765 | acc 0.7902 | f1 0.7888 | prec 0.8467 | recall 0.7383 | roc auc 0.8678 | pr auc 0.8959 | elapsed 7.00s\n",
      "train epoch 05/15 | batch 829/828 | loss 0.3670 | val loss 0.4136 | acc 0.8193 | f1 0.8212 | prec 0.8643 | recall 0.7823 | roc auc 0.8961 | pr auc 0.9190 | elapsed 6.96s\n",
      "train epoch 06/15 | batch 829/828 | loss 0.3096 | val loss 0.3708 | acc 0.8346 | f1 0.8383 | prec 0.8710 | recall 0.8080 | roc auc 0.9147 | pr auc 0.9337 | elapsed 7.27s\n",
      "train epoch 07/15 | batch 829/828 | loss 0.2685 | val loss 0.3408 | acc 0.8478 | f1 0.8520 | prec 0.8798 | recall 0.8260 | roc auc 0.9273 | pr auc 0.9435 | elapsed 7.14s\n",
      "train epoch 08/15 | batch 829/828 | loss 0.2383 | val loss 0.3192 | acc 0.8578 | f1 0.8627 | prec 0.8842 | recall 0.8423 | roc auc 0.9361 | pr auc 0.9502 | elapsed 6.97s\n",
      "train epoch 09/15 | batch 829/828 | loss 0.2148 | val loss 0.3036 | acc 0.8649 | f1 0.8702 | prec 0.8874 | recall 0.8537 | roc auc 0.9424 | pr auc 0.9549 | elapsed 7.05s\n",
      "train epoch 10/15 | batch 829/828 | loss 0.1963 | val loss 0.2920 | acc 0.8684 | f1 0.8739 | prec 0.8887 | recall 0.8597 | roc auc 0.9471 | pr auc 0.9583 | elapsed 6.95s\n",
      "train epoch 11/15 | batch 829/828 | loss 0.1810 | val loss 0.2829 | acc 0.8728 | f1 0.8785 | prec 0.8907 | recall 0.8666 | roc auc 0.9506 | pr auc 0.9609 | elapsed 8.24s\n",
      "train epoch 12/15 | batch 829/828 | loss 0.1682 | val loss 0.2762 | acc 0.8762 | f1 0.8818 | prec 0.8931 | recall 0.8709 | roc auc 0.9532 | pr auc 0.9628 | elapsed 7.40s\n",
      "train epoch 13/15 | batch 829/828 | loss 0.1572 | val loss 0.2713 | acc 0.8784 | f1 0.8842 | prec 0.8940 | recall 0.8746 | roc auc 0.9551 | pr auc 0.9643 | elapsed 7.85s\n",
      "train epoch 14/15 | batch 829/828 | loss 0.1475 | val loss 0.2674 | acc 0.8806 | f1 0.8863 | prec 0.8953 | recall 0.8774 | roc auc 0.9567 | pr auc 0.9654 | elapsed 8.04s\n",
      "train epoch 15/15 | batch 829/828 | loss 0.1389 | val loss 0.2646 | acc 0.8819 | f1 0.8878 | prec 0.8954 | recall 0.8803 | roc auc 0.9579 | pr auc 0.9663 | elapsed 7.53s\n",
      "Complexity threshold 19\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 844/843 | loss 1.2005 | val loss 1.2248 | acc 0.5580 | f1 0.4649 | prec 0.6565 | recall 0.3598 | roc auc 0.5847 | pr auc 0.6674 | elapsed 3.63s\n",
      "train epoch 01/15 | batch 844/843 | loss 1.0661 | val loss 0.9489 | acc 0.6157 | f1 0.5548 | prec 0.7264 | recall 0.4488 | roc auc 0.6760 | pr auc 0.7340 | elapsed 7.28s\n",
      "train epoch 02/15 | batch 844/843 | loss 0.7891 | val loss 0.7202 | acc 0.6828 | f1 0.6541 | prec 0.7822 | recall 0.5621 | roc auc 0.7640 | pr auc 0.8041 | elapsed 7.12s\n",
      "train epoch 03/15 | batch 844/843 | loss 0.5783 | val loss 0.5656 | acc 0.7473 | f1 0.7388 | prec 0.8237 | recall 0.6697 | roc auc 0.8302 | pr auc 0.8604 | elapsed 7.28s\n",
      "train epoch 04/15 | batch 844/843 | loss 0.4442 | val loss 0.4705 | acc 0.7967 | f1 0.7970 | prec 0.8528 | recall 0.7481 | roc auc 0.8722 | pr auc 0.8969 | elapsed 7.22s\n",
      "train epoch 05/15 | batch 844/843 | loss 0.3592 | val loss 0.4096 | acc 0.8253 | f1 0.8289 | prec 0.8681 | recall 0.7930 | roc auc 0.8986 | pr auc 0.9193 | elapsed 7.22s\n",
      "train epoch 06/15 | batch 844/843 | loss 0.3023 | val loss 0.3692 | acc 0.8433 | f1 0.8480 | prec 0.8786 | recall 0.8195 | roc auc 0.9158 | pr auc 0.9334 | elapsed 7.44s\n",
      "train epoch 07/15 | batch 844/843 | loss 0.2618 | val loss 0.3409 | acc 0.8549 | f1 0.8605 | prec 0.8834 | recall 0.8388 | roc auc 0.9276 | pr auc 0.9429 | elapsed 7.40s\n",
      "train epoch 08/15 | batch 844/843 | loss 0.2319 | val loss 0.3206 | acc 0.8641 | f1 0.8706 | prec 0.8850 | recall 0.8566 | roc auc 0.9358 | pr auc 0.9494 | elapsed 7.47s\n",
      "train epoch 09/15 | batch 844/843 | loss 0.2089 | val loss 0.3058 | acc 0.8711 | f1 0.8775 | prec 0.8901 | recall 0.8653 | roc auc 0.9418 | pr auc 0.9541 | elapsed 7.43s\n",
      "train epoch 10/15 | batch 844/843 | loss 0.1907 | val loss 0.2950 | acc 0.8759 | f1 0.8823 | prec 0.8929 | recall 0.8720 | roc auc 0.9461 | pr auc 0.9574 | elapsed 7.38s\n",
      "train epoch 11/15 | batch 844/843 | loss 0.1757 | val loss 0.2870 | acc 0.8796 | f1 0.8860 | prec 0.8952 | recall 0.8770 | roc auc 0.9494 | pr auc 0.9600 | elapsed 7.21s\n",
      "train epoch 12/15 | batch 844/843 | loss 0.1634 | val loss 0.2809 | acc 0.8821 | f1 0.8887 | prec 0.8957 | recall 0.8817 | roc auc 0.9519 | pr auc 0.9619 | elapsed 7.17s\n",
      "train epoch 13/15 | batch 844/843 | loss 0.1521 | val loss 0.2762 | acc 0.8838 | f1 0.8904 | prec 0.8960 | recall 0.8848 | roc auc 0.9538 | pr auc 0.9634 | elapsed 7.19s\n",
      "train epoch 14/15 | batch 844/843 | loss 0.1426 | val loss 0.2729 | acc 0.8854 | f1 0.8922 | prec 0.8959 | recall 0.8884 | roc auc 0.9552 | pr auc 0.9645 | elapsed 7.22s\n",
      "train epoch 15/15 | batch 844/843 | loss 0.1344 | val loss 0.2704 | acc 0.8869 | f1 0.8936 | prec 0.8967 | recall 0.8907 | roc auc 0.9563 | pr auc 0.9653 | elapsed 7.26s\n",
      "Complexity threshold 20\n",
      "created 20 encoders with 1440 parameters each\n",
      "train epoch 00/15 | batch 860/859 | loss 1.2171 | val loss 1.2148 | acc 0.5582 | f1 0.4698 | prec 0.6591 | recall 0.3649 | roc auc 0.5840 | pr auc 0.6722 | elapsed 3.74s\n",
      "train epoch 01/15 | batch 860/859 | loss 1.0741 | val loss 0.9325 | acc 0.6223 | f1 0.5658 | prec 0.7377 | recall 0.4589 | roc auc 0.6800 | pr auc 0.7436 | elapsed 8.04s\n",
      "train epoch 02/15 | batch 860/859 | loss 0.7859 | val loss 0.7011 | acc 0.6892 | f1 0.6637 | prec 0.7907 | recall 0.5719 | roc auc 0.7716 | pr auc 0.8165 | elapsed 7.47s\n",
      "train epoch 03/15 | batch 860/859 | loss 0.5722 | val loss 0.5465 | acc 0.7562 | f1 0.7497 | prec 0.8342 | recall 0.6808 | roc auc 0.8392 | pr auc 0.8732 | elapsed 7.42s\n",
      "train epoch 04/15 | batch 860/859 | loss 0.4360 | val loss 0.4540 | acc 0.8058 | f1 0.8077 | prec 0.8608 | recall 0.7609 | roc auc 0.8800 | pr auc 0.9083 | elapsed 7.37s\n",
      "train epoch 05/15 | batch 860/859 | loss 0.3509 | val loss 0.3966 | acc 0.8319 | f1 0.8366 | prec 0.8737 | recall 0.8026 | roc auc 0.9044 | pr auc 0.9286 | elapsed 7.38s\n",
      "train epoch 06/15 | batch 860/859 | loss 0.2947 | val loss 0.3591 | acc 0.8478 | f1 0.8534 | prec 0.8825 | recall 0.8263 | roc auc 0.9199 | pr auc 0.9408 | elapsed 7.32s\n",
      "train epoch 07/15 | batch 860/859 | loss 0.2552 | val loss 0.3334 | acc 0.8570 | f1 0.8633 | prec 0.8859 | recall 0.8418 | roc auc 0.9303 | pr auc 0.9485 | elapsed 7.44s\n",
      "train epoch 08/15 | batch 860/859 | loss 0.2263 | val loss 0.3149 | acc 0.8621 | f1 0.8688 | prec 0.8873 | recall 0.8510 | roc auc 0.9375 | pr auc 0.9537 | elapsed 7.45s\n",
      "train epoch 09/15 | batch 860/859 | loss 0.2045 | val loss 0.3018 | acc 0.8686 | f1 0.8751 | prec 0.8920 | recall 0.8589 | roc auc 0.9426 | pr auc 0.9573 | elapsed 7.44s\n",
      "train epoch 10/15 | batch 860/859 | loss 0.1871 | val loss 0.2919 | acc 0.8737 | f1 0.8803 | prec 0.8948 | recall 0.8663 | roc auc 0.9465 | pr auc 0.9600 | elapsed 7.29s\n",
      "train epoch 11/15 | batch 860/859 | loss 0.1730 | val loss 0.2848 | acc 0.8748 | f1 0.8816 | prec 0.8946 | recall 0.8690 | roc auc 0.9493 | pr auc 0.9619 | elapsed 7.48s\n",
      "train epoch 12/15 | batch 860/859 | loss 0.1611 | val loss 0.2792 | acc 0.8775 | f1 0.8843 | prec 0.8958 | recall 0.8731 | roc auc 0.9515 | pr auc 0.9634 | elapsed 7.44s\n",
      "train epoch 13/15 | batch 860/859 | loss 0.1508 | val loss 0.2750 | acc 0.8786 | f1 0.8855 | prec 0.8965 | recall 0.8747 | roc auc 0.9531 | pr auc 0.9645 | elapsed 7.47s\n",
      "train epoch 14/15 | batch 860/859 | loss 0.1417 | val loss 0.2722 | acc 0.8830 | f1 0.8897 | prec 0.9000 | recall 0.8796 | roc auc 0.9544 | pr auc 0.9653 | elapsed 7.52s\n",
      "train epoch 15/15 | batch 860/859 | loss 0.1337 | val loss 0.2699 | acc 0.8851 | f1 0.8917 | prec 0.9010 | recall 0.8826 | roc auc 0.9554 | pr auc 0.9661 | elapsed 7.50s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.reasoner import ReasonerHead, EmbeddingLayer, train\n",
    "from src.utils import timestr, paramcount\n",
    "import torch as T\n",
    "from src.elpp.gen import split_dataset\n",
    "\n",
    "seed = 2022\n",
    "ts = timestr()\n",
    "\n",
    "emb_size = 10\n",
    "hidden_size = 16\n",
    "epoch_count = 15\n",
    "test_epoch_count = 10\n",
    "batch_size = 32\n",
    "\n",
    "test_artifacts = {}\n",
    "\n",
    "for complexity_threshold in range(2, 21):\n",
    "\n",
    "    print(\"Complexity threshold\", complexity_threshold)\n",
    "\n",
    "    training, validation, test = split_dataset(test_reasoners, np.random.default_rng(seed=0xbeef), complexity_threshold=complexity_threshold)\n",
    "\n",
    "    T.manual_seed(seed)\n",
    "    reasoner = best_neural_reasoner\n",
    "    encoders = [EmbeddingLayer(emb_size=emb_size, n_concepts=reasoner.n_concepts, n_roles=reasoner.n_roles) for reasoner in\n",
    "                test_reasoners]\n",
    "\n",
    "    print(f'created {len(encoders)} encoders with {paramcount(encoders[0])} parameters each')\n",
    "\n",
    "    train_logger = train(training, validation, reasoner, encoders, epoch_count=epoch_count, batch_size=batch_size, freeze_reasoner=True)\n",
    "\n",
    "    test_artifacts[complexity_threshold] = {\n",
    "        'encoders': encoders,\n",
    "        'training': training,\n",
    "        'validation': validation,\n",
    "        'test': test\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp = {key: {'encoders': [e.state_dict() for e in value['encoders']], 'training': value['training'], 'validation': value['validation'], 'test': value['test']} for key, value in test_artifacts.items()}\n",
    "\n",
    "with lzma.open(base_dir / 'exp2.dill.xz', 'wb') as f:\n",
    "    dill.dump(tmp, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.reasoner import eval_batch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for complexity_threshold, components in tqdm(artifacts.items()):\n",
    "    with T.no_grad():\n",
    "        idx_te, X_te, y_te = components['test']\n",
    "        _, _, Y_te_good = eval_batch(best_neural_reasoner, components['encoders'], X_te, y_te, idx_te)\n",
    "    for i in range(len(idx_te)):\n",
    "        idx = idx_te[i]\n",
    "        axiom = X_te[i]\n",
    "        expected = y_te[i]\n",
    "        predicted = Y_te_good[i]\n",
    "        complexity = len(reasoners[idx].decode_shortest_proof(axiom[1], axiom[2]))\n",
    "        rows.append([complexity_threshold, idx, complexity, axiom, expected, int(predicted >= .5), predicted])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:23<00:00,  1.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Complexity threshold  KB  Complexity        Axiom  Expected  Predicted\n0                          2   0           9   (0, 4, 53)         1          0\n1                          2   0           3   (0, 7, 53)         1          0\n2                          2   0           8    (0, 9, 0)         1          0\n3                          2   0          10   (0, 9, 46)         1          0\n4                          2   0           7   (0, 9, 53)         1          0\n...                      ...  ..         ...          ...       ...        ...\n311003                    20  17          22  (0, 96, 66)         1          1\n311004                    20  17          23   (0, 98, 5)         1          1\n311005                    20  17          21  (0, 98, 10)         1          1\n311006                    20  17          22  (0, 98, 48)         1          1\n311007                    20  17          22  (0, 98, 57)         1          1\n\n[311008 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Complexity threshold</th>\n      <th>KB</th>\n      <th>Complexity</th>\n      <th>Axiom</th>\n      <th>Expected</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>(0, 4, 53)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>(0, 7, 53)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>8</td>\n      <td>(0, 9, 0)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>0</td>\n      <td>10</td>\n      <td>(0, 9, 46)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>0</td>\n      <td>7</td>\n      <td>(0, 9, 53)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>311003</th>\n      <td>20</td>\n      <td>17</td>\n      <td>22</td>\n      <td>(0, 96, 66)</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>311004</th>\n      <td>20</td>\n      <td>17</td>\n      <td>23</td>\n      <td>(0, 98, 5)</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>311005</th>\n      <td>20</td>\n      <td>17</td>\n      <td>21</td>\n      <td>(0, 98, 10)</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>311006</th>\n      <td>20</td>\n      <td>17</td>\n      <td>22</td>\n      <td>(0, 98, 48)</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>311007</th>\n      <td>20</td>\n      <td>17</td>\n      <td>22</td>\n      <td>(0, 98, 57)</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>311008 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows, columns=[\"Complexity threshold\", \"KB\", \"Complexity\", \"Axiom\", \"Expected\", \"Predicted\", \"Raw predicted\"])\n",
    "df.to_feather(base_dir / 'exp2.feather')\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "reasonable-embeddings",
   "language": "python",
   "display_name": "reasonable-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
