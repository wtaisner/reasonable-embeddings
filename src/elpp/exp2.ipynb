{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wtaisner/PycharmProjects/reasonable-embeddings\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_dir = Path('local/out/elpp/')\n",
    "\n",
    "base_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lzma\n",
    "import dill\n",
    "\n",
    "with lzma.open(base_dir / 'reasoners.dill.xz', 'rb') as f:\n",
    "    reasoners = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.reasoner import ReasonerHead\n",
    "from src.reasoner import EmbeddingLayer\n",
    "\n",
    "with lzma.open(base_dir / 'exp1.dill.xz', 'rb') as f:\n",
    "    artifacts: dict = dill.load(f)\n",
    "\n",
    "emb_size = 32\n",
    "hidden_size = 16\n",
    "\n",
    "for key, components in artifacts.items():\n",
    "    neural_reasoner = ReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "    neural_reasoner.load_state_dict(components['reasoner'])\n",
    "    components['reasoner'] = neural_reasoner\n",
    "    encoders = [EmbeddingLayer(emb_size=emb_size, n_concepts=reasoner.n_concepts, n_roles=reasoner.n_roles) for reasoner in\n",
    "                reasoners]\n",
    "    for sd, e in zip(components['encoders'], encoders):\n",
    "        e.load_state_dict(sd)\n",
    "    components['encoders'] = encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with lzma.open(base_dir / 'test_reasoners.dill.xz', 'rb') as f:\n",
    "    test_reasoners = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_neural_reasoner = artifacts[max(artifacts.keys())]['reasoner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity threshold 2\n",
      "Training 10202 #pos 5101\n",
      "Validation 2528 #pos 1264\n",
      "Test 22480 #pos 22480\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 81/80 | loss 0.8342 | val loss 0.8140 | acc 0.7516 | f1 0.7422 | prec 0.7713 | recall 0.7152 | roc auc 0.8145 | pr auc 0.8621 | elapsed 0.90s\n",
      "train epoch 01/15 | batch 81/80 | loss 0.8168 | val loss 0.7775 | acc 0.7575 | f1 0.7478 | prec 0.7789 | recall 0.7191 | roc auc 0.8217 | pr auc 0.8666 | elapsed 2.04s\n",
      "train epoch 02/15 | batch 81/80 | loss 0.7428 | val loss 0.7409 | acc 0.7638 | f1 0.7538 | prec 0.7873 | recall 0.7231 | roc auc 0.8292 | pr auc 0.8714 | elapsed 2.23s\n",
      "train epoch 03/15 | batch 81/80 | loss 0.6732 | val loss 0.7090 | acc 0.7702 | f1 0.7596 | prec 0.7962 | recall 0.7263 | roc auc 0.8361 | pr auc 0.8761 | elapsed 2.12s\n",
      "train epoch 04/15 | batch 81/80 | loss 0.6112 | val loss 0.6810 | acc 0.7765 | f1 0.7670 | prec 0.8010 | recall 0.7358 | roc auc 0.8424 | pr auc 0.8804 | elapsed 2.52s\n",
      "train epoch 05/15 | batch 81/80 | loss 0.5560 | val loss 0.6570 | acc 0.7797 | f1 0.7699 | prec 0.8055 | recall 0.7373 | roc auc 0.8483 | pr auc 0.8846 | elapsed 2.29s\n",
      "train epoch 06/15 | batch 81/80 | loss 0.5052 | val loss 0.6358 | acc 0.7884 | f1 0.7790 | prec 0.8150 | recall 0.7460 | roc auc 0.8535 | pr auc 0.8883 | elapsed 2.22s\n",
      "train epoch 07/15 | batch 81/80 | loss 0.4595 | val loss 0.6175 | acc 0.7915 | f1 0.7821 | prec 0.8190 | recall 0.7484 | roc auc 0.8581 | pr auc 0.8916 | elapsed 2.14s\n",
      "train epoch 08/15 | batch 81/80 | loss 0.4189 | val loss 0.6016 | acc 0.7951 | f1 0.7861 | prec 0.8221 | recall 0.7532 | roc auc 0.8622 | pr auc 0.8946 | elapsed 2.15s\n",
      "train epoch 09/15 | batch 81/80 | loss 0.3818 | val loss 0.5877 | acc 0.7983 | f1 0.7901 | prec 0.8233 | recall 0.7595 | roc auc 0.8661 | pr auc 0.8973 | elapsed 2.12s\n",
      "train epoch 10/15 | batch 81/80 | loss 0.3493 | val loss 0.5750 | acc 0.8030 | f1 0.7952 | prec 0.8279 | recall 0.7650 | roc auc 0.8695 | pr auc 0.8998 | elapsed 2.05s\n",
      "train epoch 11/15 | batch 81/80 | loss 0.3185 | val loss 0.5642 | acc 0.8085 | f1 0.8008 | prec 0.8345 | recall 0.7698 | roc auc 0.8725 | pr auc 0.9019 | elapsed 2.54s\n",
      "train epoch 12/15 | batch 81/80 | loss 0.2911 | val loss 0.5550 | acc 0.8109 | f1 0.8035 | prec 0.8365 | recall 0.7729 | roc auc 0.8751 | pr auc 0.9038 | elapsed 2.39s\n",
      "train epoch 13/15 | batch 81/80 | loss 0.2662 | val loss 0.5466 | acc 0.8149 | f1 0.8076 | prec 0.8408 | recall 0.7769 | roc auc 0.8774 | pr auc 0.9055 | elapsed 2.43s\n",
      "train epoch 14/15 | batch 81/80 | loss 0.2447 | val loss 0.5389 | acc 0.8188 | f1 0.8120 | prec 0.8439 | recall 0.7824 | roc auc 0.8798 | pr auc 0.9072 | elapsed 2.38s\n",
      "train epoch 15/15 | batch 81/80 | loss 0.2236 | val loss 0.5327 | acc 0.8200 | f1 0.8134 | prec 0.8443 | recall 0.7848 | roc auc 0.8817 | pr auc 0.9085 | elapsed 2.38s\n",
      "Complexity threshold 3\n",
      "Training 11504 #pos 5752\n",
      "Validation 2856 #pos 1428\n",
      "Test 21665 #pos 21665\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 91/90 | loss 0.9380 | val loss 0.9337 | acc 0.7279 | f1 0.7100 | prec 0.7602 | recall 0.6660 | roc auc 0.7795 | pr auc 0.8369 | elapsed 1.16s\n",
      "train epoch 01/15 | batch 91/90 | loss 0.9124 | val loss 0.8825 | acc 0.7342 | f1 0.7165 | prec 0.7678 | recall 0.6716 | roc auc 0.7900 | pr auc 0.8436 | elapsed 2.69s\n",
      "train epoch 02/15 | batch 91/90 | loss 0.8198 | val loss 0.8328 | acc 0.7412 | f1 0.7242 | prec 0.7754 | recall 0.6793 | roc auc 0.8006 | pr auc 0.8507 | elapsed 2.83s\n",
      "train epoch 03/15 | batch 91/90 | loss 0.7346 | val loss 0.7886 | acc 0.7489 | f1 0.7326 | prec 0.7837 | recall 0.6877 | roc auc 0.8106 | pr auc 0.8575 | elapsed 2.73s\n",
      "train epoch 04/15 | batch 91/90 | loss 0.6577 | val loss 0.7480 | acc 0.7570 | f1 0.7403 | prec 0.7950 | recall 0.6926 | roc auc 0.8200 | pr auc 0.8640 | elapsed 2.84s\n",
      "train epoch 05/15 | batch 91/90 | loss 0.5894 | val loss 0.7125 | acc 0.7609 | f1 0.7454 | prec 0.7968 | recall 0.7003 | roc auc 0.8289 | pr auc 0.8703 | elapsed 2.84s\n",
      "train epoch 06/15 | batch 91/90 | loss 0.5288 | val loss 0.6807 | acc 0.7703 | f1 0.7561 | prec 0.8059 | recall 0.7122 | roc auc 0.8366 | pr auc 0.8759 | elapsed 2.71s\n",
      "train epoch 07/15 | batch 91/90 | loss 0.4745 | val loss 0.6530 | acc 0.7777 | f1 0.7635 | prec 0.8154 | recall 0.7178 | roc auc 0.8440 | pr auc 0.8812 | elapsed 2.74s\n",
      "train epoch 08/15 | batch 91/90 | loss 0.4264 | val loss 0.6292 | acc 0.7819 | f1 0.7687 | prec 0.8182 | recall 0.7248 | roc auc 0.8504 | pr auc 0.8859 | elapsed 2.95s\n",
      "train epoch 09/15 | batch 91/90 | loss 0.3837 | val loss 0.6078 | acc 0.7917 | f1 0.7805 | prec 0.8246 | recall 0.7409 | roc auc 0.8563 | pr auc 0.8901 | elapsed 3.18s\n",
      "train epoch 10/15 | batch 91/90 | loss 0.3458 | val loss 0.5893 | acc 0.7962 | f1 0.7854 | prec 0.8294 | recall 0.7458 | roc auc 0.8616 | pr auc 0.8939 | elapsed 3.05s\n",
      "train epoch 11/15 | batch 91/90 | loss 0.3124 | val loss 0.5733 | acc 0.7997 | f1 0.7899 | prec 0.8308 | recall 0.7528 | roc auc 0.8664 | pr auc 0.8973 | elapsed 4.56s\n",
      "train epoch 12/15 | batch 91/90 | loss 0.2826 | val loss 0.5583 | acc 0.8060 | f1 0.7965 | prec 0.8377 | recall 0.7591 | roc auc 0.8710 | pr auc 0.9005 | elapsed 3.77s\n",
      "train epoch 13/15 | batch 91/90 | loss 0.2560 | val loss 0.5455 | acc 0.8074 | f1 0.7991 | prec 0.8351 | recall 0.7661 | roc auc 0.8750 | pr auc 0.9032 | elapsed 2.71s\n",
      "train epoch 14/15 | batch 91/90 | loss 0.2327 | val loss 0.5346 | acc 0.8092 | f1 0.8016 | prec 0.8347 | recall 0.7710 | roc auc 0.8784 | pr auc 0.9057 | elapsed 2.57s\n",
      "train epoch 15/15 | batch 91/90 | loss 0.2119 | val loss 0.5244 | acc 0.8127 | f1 0.8061 | prec 0.8355 | recall 0.7787 | roc auc 0.8818 | pr auc 0.9080 | elapsed 2.77s\n",
      "Complexity threshold 4\n",
      "Training 12822 #pos 6411\n",
      "Validation 3184 #pos 1592\n",
      "Test 20842 #pos 20842\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 102/101 | loss 1.0204 | val loss 1.0084 | acc 0.6985 | f1 0.6664 | prec 0.7457 | recall 0.6024 | roc auc 0.7484 | pr auc 0.8111 | elapsed 1.13s\n",
      "train epoch 01/15 | batch 102/101 | loss 0.9833 | val loss 0.9306 | acc 0.7117 | f1 0.6824 | prec 0.7596 | recall 0.6193 | roc auc 0.7662 | pr auc 0.8225 | elapsed 2.95s\n",
      "train epoch 02/15 | batch 102/101 | loss 0.8731 | val loss 0.8595 | acc 0.7255 | f1 0.6978 | prec 0.7762 | recall 0.6338 | roc auc 0.7832 | pr auc 0.8340 | elapsed 2.86s\n",
      "train epoch 03/15 | batch 102/101 | loss 0.7703 | val loss 0.7970 | acc 0.7378 | f1 0.7120 | prec 0.7896 | recall 0.6482 | roc auc 0.7990 | pr auc 0.8450 | elapsed 3.06s\n",
      "train epoch 04/15 | batch 102/101 | loss 0.6865 | val loss 0.7433 | acc 0.7500 | f1 0.7265 | prec 0.8020 | recall 0.6639 | roc auc 0.8132 | pr auc 0.8552 | elapsed 3.14s\n",
      "train epoch 05/15 | batch 102/101 | loss 0.6050 | val loss 0.6974 | acc 0.7613 | f1 0.7410 | prec 0.8100 | recall 0.6828 | roc auc 0.8257 | pr auc 0.8644 | elapsed 3.11s\n",
      "train epoch 06/15 | batch 102/101 | loss 0.5380 | val loss 0.6584 | acc 0.7723 | f1 0.7538 | prec 0.8204 | recall 0.6972 | roc auc 0.8366 | pr auc 0.8726 | elapsed 3.36s\n",
      "train epoch 07/15 | batch 102/101 | loss 0.4795 | val loss 0.6252 | acc 0.7817 | f1 0.7653 | prec 0.8276 | recall 0.7117 | roc auc 0.8462 | pr auc 0.8798 | elapsed 3.07s\n",
      "train epoch 08/15 | batch 102/101 | loss 0.4268 | val loss 0.5970 | acc 0.7880 | f1 0.7733 | prec 0.8310 | recall 0.7230 | roc auc 0.8546 | pr auc 0.8860 | elapsed 3.40s\n",
      "train epoch 09/15 | batch 102/101 | loss 0.3794 | val loss 0.5727 | acc 0.7930 | f1 0.7798 | prec 0.8330 | recall 0.7330 | roc auc 0.8620 | pr auc 0.8915 | elapsed 3.30s\n",
      "train epoch 10/15 | batch 102/101 | loss 0.3378 | val loss 0.5522 | acc 0.7971 | f1 0.7857 | prec 0.8326 | recall 0.7437 | roc auc 0.8684 | pr auc 0.8962 | elapsed 3.04s\n",
      "train epoch 11/15 | batch 102/101 | loss 0.3032 | val loss 0.5346 | acc 0.8031 | f1 0.7927 | prec 0.8367 | recall 0.7531 | roc auc 0.8740 | pr auc 0.9004 | elapsed 3.06s\n",
      "train epoch 12/15 | batch 102/101 | loss 0.2716 | val loss 0.5193 | acc 0.8053 | f1 0.7959 | prec 0.8361 | recall 0.7594 | roc auc 0.8790 | pr auc 0.9040 | elapsed 5.11s\n",
      "train epoch 13/15 | batch 102/101 | loss 0.2475 | val loss 0.5069 | acc 0.8109 | f1 0.8024 | prec 0.8404 | recall 0.7676 | roc auc 0.8834 | pr auc 0.9071 | elapsed 3.06s\n",
      "train epoch 14/15 | batch 102/101 | loss 0.2218 | val loss 0.4960 | acc 0.8172 | f1 0.8094 | prec 0.8454 | recall 0.7764 | roc auc 0.8873 | pr auc 0.9099 | elapsed 3.09s\n",
      "train epoch 15/15 | batch 102/101 | loss 0.2039 | val loss 0.4870 | acc 0.8188 | f1 0.8116 | prec 0.8450 | recall 0.7808 | roc auc 0.8907 | pr auc 0.9123 | elapsed 3.29s\n",
      "Complexity threshold 5\n",
      "Training 13946 #pos 6973\n",
      "Validation 3464 #pos 1732\n",
      "Test 20140 #pos 20140\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 110/109 | loss 1.1145 | val loss 1.0776 | acc 0.6902 | f1 0.6490 | prec 0.7487 | recall 0.5727 | roc auc 0.7314 | pr auc 0.7967 | elapsed 1.41s\n",
      "train epoch 01/15 | batch 110/109 | loss 1.0688 | val loss 0.9858 | acc 0.7006 | f1 0.6623 | prec 0.7595 | recall 0.5872 | roc auc 0.7521 | pr auc 0.8101 | elapsed 3.09s\n",
      "train epoch 02/15 | batch 110/109 | loss 0.9378 | val loss 0.8997 | acc 0.7142 | f1 0.6788 | prec 0.7748 | recall 0.6039 | roc auc 0.7721 | pr auc 0.8236 | elapsed 3.39s\n",
      "train epoch 03/15 | batch 110/109 | loss 0.8201 | val loss 0.8228 | acc 0.7234 | f1 0.6914 | prec 0.7821 | recall 0.6195 | roc auc 0.7914 | pr auc 0.8369 | elapsed 3.60s\n",
      "train epoch 04/15 | batch 110/109 | loss 0.7163 | val loss 0.7571 | acc 0.7387 | f1 0.7104 | prec 0.7968 | recall 0.6409 | roc auc 0.8087 | pr auc 0.8493 | elapsed 3.06s\n",
      "train epoch 05/15 | batch 110/109 | loss 0.6263 | val loss 0.6999 | acc 0.7532 | f1 0.7293 | prec 0.8073 | recall 0.6651 | roc auc 0.8247 | pr auc 0.8609 | elapsed 3.19s\n",
      "train epoch 06/15 | batch 110/109 | loss 0.5486 | val loss 0.6528 | acc 0.7665 | f1 0.7454 | prec 0.8194 | recall 0.6836 | roc auc 0.8382 | pr auc 0.8708 | elapsed 3.10s\n",
      "train epoch 07/15 | batch 110/109 | loss 0.4819 | val loss 0.6115 | acc 0.7774 | f1 0.7594 | prec 0.8262 | recall 0.7027 | roc auc 0.8503 | pr auc 0.8798 | elapsed 3.69s\n",
      "train epoch 08/15 | batch 110/109 | loss 0.4244 | val loss 0.5772 | acc 0.7890 | f1 0.7743 | prec 0.8321 | recall 0.7240 | roc auc 0.8608 | pr auc 0.8875 | elapsed 3.64s\n",
      "train epoch 09/15 | batch 110/109 | loss 0.3755 | val loss 0.5480 | acc 0.7968 | f1 0.7837 | prec 0.8377 | recall 0.7361 | roc auc 0.8701 | pr auc 0.8943 | elapsed 3.24s\n",
      "train epoch 10/15 | batch 110/109 | loss 0.3334 | val loss 0.5230 | acc 0.8017 | f1 0.7897 | prec 0.8404 | recall 0.7448 | roc auc 0.8782 | pr auc 0.9003 | elapsed 3.33s\n",
      "train epoch 11/15 | batch 110/109 | loss 0.2973 | val loss 0.5015 | acc 0.8069 | f1 0.7965 | prec 0.8418 | recall 0.7558 | roc auc 0.8854 | pr auc 0.9056 | elapsed 3.23s\n",
      "train epoch 12/15 | batch 110/109 | loss 0.2664 | val loss 0.4840 | acc 0.8144 | f1 0.8054 | prec 0.8462 | recall 0.7685 | roc auc 0.8913 | pr auc 0.9100 | elapsed 3.24s\n",
      "train epoch 13/15 | batch 110/109 | loss 0.2398 | val loss 0.4689 | acc 0.8199 | f1 0.8123 | prec 0.8480 | recall 0.7794 | roc auc 0.8965 | pr auc 0.9138 | elapsed 3.32s\n",
      "train epoch 14/15 | batch 110/109 | loss 0.2169 | val loss 0.4562 | acc 0.8248 | f1 0.8184 | prec 0.8492 | recall 0.7898 | roc auc 0.9009 | pr auc 0.9172 | elapsed 3.17s\n",
      "train epoch 15/15 | batch 110/109 | loss 0.1972 | val loss 0.4455 | acc 0.8297 | f1 0.8246 | prec 0.8499 | recall 0.8008 | roc auc 0.9047 | pr auc 0.9201 | elapsed 3.20s\n",
      "Complexity threshold 6\n",
      "Training 14814 #pos 7407\n",
      "Validation 3686 #pos 1843\n",
      "Test 19595 #pos 19595\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 117/116 | loss 1.1144 | val loss 1.2159 | acc 0.6622 | f1 0.6142 | prec 0.7160 | recall 0.5377 | roc auc 0.6903 | pr auc 0.7619 | elapsed 1.47s\n",
      "train epoch 01/15 | batch 117/116 | loss 1.0645 | val loss 1.1080 | acc 0.6755 | f1 0.6320 | prec 0.7299 | recall 0.5572 | roc auc 0.7151 | pr auc 0.7779 | elapsed 3.33s\n",
      "train epoch 02/15 | batch 117/116 | loss 0.9254 | val loss 1.0069 | acc 0.6907 | f1 0.6514 | prec 0.7463 | recall 0.5779 | roc auc 0.7393 | pr auc 0.7941 | elapsed 3.47s\n",
      "train epoch 03/15 | batch 117/116 | loss 0.7993 | val loss 0.9179 | acc 0.7037 | f1 0.6681 | prec 0.7595 | recall 0.5963 | roc auc 0.7619 | pr auc 0.8097 | elapsed 3.51s\n",
      "train epoch 04/15 | batch 117/116 | loss 0.6905 | val loss 0.8395 | acc 0.7198 | f1 0.6899 | prec 0.7722 | recall 0.6234 | roc auc 0.7833 | pr auc 0.8250 | elapsed 3.37s\n",
      "train epoch 05/15 | batch 117/116 | loss 0.5972 | val loss 0.7734 | acc 0.7347 | f1 0.7098 | prec 0.7832 | recall 0.6489 | roc auc 0.8022 | pr auc 0.8389 | elapsed 3.49s\n",
      "train epoch 06/15 | batch 117/116 | loss 0.5172 | val loss 0.7165 | acc 0.7504 | f1 0.7281 | prec 0.7995 | recall 0.6685 | roc auc 0.8189 | pr auc 0.8514 | elapsed 3.46s\n",
      "train epoch 07/15 | batch 117/116 | loss 0.4498 | val loss 0.6679 | acc 0.7661 | f1 0.7471 | prec 0.8134 | recall 0.6907 | roc auc 0.8336 | pr auc 0.8626 | elapsed 3.33s\n",
      "train epoch 08/15 | batch 117/116 | loss 0.3931 | val loss 0.6277 | acc 0.7789 | f1 0.7637 | prec 0.8200 | recall 0.7146 | roc auc 0.8461 | pr auc 0.8722 | elapsed 3.80s\n",
      "train epoch 09/15 | batch 117/116 | loss 0.3447 | val loss 0.5934 | acc 0.7889 | f1 0.7762 | prec 0.8261 | recall 0.7320 | roc auc 0.8568 | pr auc 0.8805 | elapsed 3.37s\n",
      "train epoch 10/15 | batch 117/116 | loss 0.3042 | val loss 0.5646 | acc 0.7973 | f1 0.7869 | prec 0.8297 | recall 0.7482 | roc auc 0.8661 | pr auc 0.8879 | elapsed 3.51s\n",
      "train epoch 11/15 | batch 117/116 | loss 0.2703 | val loss 0.5411 | acc 0.8030 | f1 0.7949 | prec 0.8291 | recall 0.7634 | roc auc 0.8738 | pr auc 0.8939 | elapsed 3.43s\n",
      "train epoch 12/15 | batch 117/116 | loss 0.2417 | val loss 0.5202 | acc 0.8090 | f1 0.8020 | prec 0.8325 | recall 0.7737 | roc auc 0.8806 | pr auc 0.8993 | elapsed 3.47s\n",
      "train epoch 13/15 | batch 117/116 | loss 0.2166 | val loss 0.5025 | acc 0.8158 | f1 0.8100 | prec 0.8364 | recall 0.7851 | roc auc 0.8866 | pr auc 0.9040 | elapsed 3.49s\n",
      "train epoch 14/15 | batch 117/116 | loss 0.1958 | val loss 0.4878 | acc 0.8226 | f1 0.8177 | prec 0.8407 | recall 0.7960 | roc auc 0.8916 | pr auc 0.9080 | elapsed 3.39s\n",
      "train epoch 15/15 | batch 117/116 | loss 0.1776 | val loss 0.4750 | acc 0.8272 | f1 0.8224 | prec 0.8458 | recall 0.8003 | roc auc 0.8960 | pr auc 0.9114 | elapsed 3.40s\n",
      "Complexity threshold 7\n",
      "Training 15724 #pos 7862\n",
      "Validation 3910 #pos 1955\n",
      "Test 19028 #pos 19028\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 124/123 | loss 1.1761 | val loss 1.1654 | acc 0.6591 | f1 0.5993 | prec 0.7267 | recall 0.5100 | roc auc 0.7020 | pr auc 0.7675 | elapsed 1.53s\n",
      "train epoch 01/15 | batch 124/123 | loss 1.1190 | val loss 1.0404 | acc 0.6818 | f1 0.6273 | prec 0.7570 | recall 0.5355 | roc auc 0.7317 | pr auc 0.7875 | elapsed 3.66s\n",
      "train epoch 02/15 | batch 124/123 | loss 0.9640 | val loss 0.9272 | acc 0.7023 | f1 0.6550 | prec 0.7787 | recall 0.5652 | roc auc 0.7601 | pr auc 0.8079 | elapsed 3.61s\n",
      "train epoch 03/15 | batch 124/123 | loss 0.8260 | val loss 0.8283 | acc 0.7230 | f1 0.6832 | prec 0.7978 | recall 0.5974 | roc auc 0.7865 | pr auc 0.8274 | elapsed 4.13s\n",
      "train epoch 04/15 | batch 124/123 | loss 0.7073 | val loss 0.7456 | acc 0.7445 | f1 0.7110 | prec 0.8182 | recall 0.6286 | roc auc 0.8097 | pr auc 0.8450 | elapsed 3.91s\n",
      "train epoch 05/15 | batch 124/123 | loss 0.6056 | val loss 0.6750 | acc 0.7601 | f1 0.7328 | prec 0.8270 | recall 0.6578 | roc auc 0.8302 | pr auc 0.8608 | elapsed 3.98s\n",
      "train epoch 06/15 | batch 124/123 | loss 0.5213 | val loss 0.6168 | acc 0.7752 | f1 0.7532 | prec 0.8350 | recall 0.6859 | roc auc 0.8477 | pr auc 0.8745 | elapsed 3.65s\n",
      "train epoch 07/15 | batch 124/123 | loss 0.4506 | val loss 0.5682 | acc 0.7852 | f1 0.7660 | prec 0.8410 | recall 0.7033 | roc auc 0.8627 | pr auc 0.8864 | elapsed 3.75s\n",
      "train epoch 08/15 | batch 124/123 | loss 0.3916 | val loss 0.5285 | acc 0.8023 | f1 0.7876 | prec 0.8510 | recall 0.7330 | roc auc 0.8751 | pr auc 0.8963 | elapsed 3.66s\n",
      "train epoch 09/15 | batch 124/123 | loss 0.3423 | val loss 0.4961 | acc 0.8113 | f1 0.8000 | prec 0.8507 | recall 0.7550 | roc auc 0.8854 | pr auc 0.9046 | elapsed 3.73s\n",
      "train epoch 10/15 | batch 124/123 | loss 0.3013 | val loss 0.4686 | acc 0.8238 | f1 0.8153 | prec 0.8564 | recall 0.7780 | roc auc 0.8943 | pr auc 0.9118 | elapsed 3.76s\n",
      "train epoch 11/15 | batch 124/123 | loss 0.2671 | val loss 0.4471 | acc 0.8317 | f1 0.8252 | prec 0.8585 | recall 0.7944 | roc auc 0.9013 | pr auc 0.9175 | elapsed 3.82s\n",
      "train epoch 12/15 | batch 124/123 | loss 0.2385 | val loss 0.4288 | acc 0.8363 | f1 0.8311 | prec 0.8583 | recall 0.8056 | roc auc 0.9073 | pr auc 0.9225 | elapsed 3.72s\n",
      "train epoch 13/15 | batch 124/123 | loss 0.2144 | val loss 0.4140 | acc 0.8384 | f1 0.8336 | prec 0.8589 | recall 0.8097 | roc auc 0.9122 | pr auc 0.9265 | elapsed 3.59s\n",
      "train epoch 14/15 | batch 124/123 | loss 0.1940 | val loss 0.4019 | acc 0.8440 | f1 0.8403 | prec 0.8606 | recall 0.8210 | roc auc 0.9165 | pr auc 0.9300 | elapsed 3.89s\n",
      "train epoch 15/15 | batch 124/123 | loss 0.1762 | val loss 0.3920 | acc 0.8494 | f1 0.8465 | prec 0.8629 | recall 0.8307 | roc auc 0.9199 | pr auc 0.9327 | elapsed 4.01s\n",
      "Complexity threshold 8\n",
      "Training 16662 #pos 8331\n",
      "Validation 4146 #pos 2073\n",
      "Test 18441 #pos 18441\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 132/131 | loss 1.1983 | val loss 1.2378 | acc 0.6479 | f1 0.5859 | prec 0.7109 | recall 0.4983 | roc auc 0.6801 | pr auc 0.7514 | elapsed 1.82s\n",
      "train epoch 01/15 | batch 132/131 | loss 1.1257 | val loss 1.1007 | acc 0.6667 | f1 0.6103 | prec 0.7346 | recall 0.5219 | roc auc 0.7128 | pr auc 0.7734 | elapsed 4.62s\n",
      "train epoch 02/15 | batch 132/131 | loss 0.9597 | val loss 0.9776 | acc 0.6881 | f1 0.6387 | prec 0.7590 | recall 0.5514 | roc auc 0.7436 | pr auc 0.7953 | elapsed 4.07s\n",
      "train epoch 03/15 | batch 132/131 | loss 0.8117 | val loss 0.8709 | acc 0.7084 | f1 0.6687 | prec 0.7741 | recall 0.5885 | roc auc 0.7721 | pr auc 0.8166 | elapsed 4.43s\n",
      "train epoch 04/15 | batch 132/131 | loss 0.6854 | val loss 0.7811 | acc 0.7299 | f1 0.6968 | prec 0.7940 | recall 0.6208 | roc auc 0.7975 | pr auc 0.8359 | elapsed 4.41s\n",
      "train epoch 05/15 | batch 132/131 | loss 0.5812 | val loss 0.7064 | acc 0.7501 | f1 0.7240 | prec 0.8084 | recall 0.6556 | roc auc 0.8195 | pr auc 0.8530 | elapsed 4.44s\n",
      "train epoch 06/15 | batch 132/131 | loss 0.4918 | val loss 0.6466 | acc 0.7677 | f1 0.7464 | prec 0.8219 | recall 0.6836 | roc auc 0.8378 | pr auc 0.8673 | elapsed 4.44s\n",
      "train epoch 07/15 | batch 132/131 | loss 0.4217 | val loss 0.5971 | acc 0.7808 | f1 0.7632 | prec 0.8296 | recall 0.7067 | roc auc 0.8534 | pr auc 0.8796 | elapsed 4.20s\n",
      "train epoch 08/15 | batch 132/131 | loss 0.3621 | val loss 0.5569 | acc 0.7950 | f1 0.7810 | prec 0.8380 | recall 0.7313 | roc auc 0.8663 | pr auc 0.8896 | elapsed 4.44s\n",
      "train epoch 09/15 | batch 132/131 | loss 0.3159 | val loss 0.5238 | acc 0.8034 | f1 0.7920 | prec 0.8407 | recall 0.7487 | roc auc 0.8771 | pr auc 0.8982 | elapsed 5.01s\n",
      "train epoch 10/15 | batch 132/131 | loss 0.2772 | val loss 0.4978 | acc 0.8116 | f1 0.8024 | prec 0.8436 | recall 0.7651 | roc auc 0.8858 | pr auc 0.9052 | elapsed 6.00s\n",
      "train epoch 11/15 | batch 132/131 | loss 0.2457 | val loss 0.4768 | acc 0.8186 | f1 0.8113 | prec 0.8453 | recall 0.7800 | roc auc 0.8928 | pr auc 0.9108 | elapsed 4.47s\n",
      "train epoch 12/15 | batch 132/131 | loss 0.2198 | val loss 0.4599 | acc 0.8249 | f1 0.8189 | prec 0.8481 | recall 0.7916 | roc auc 0.8986 | pr auc 0.9155 | elapsed 4.54s\n",
      "train epoch 13/15 | batch 132/131 | loss 0.1986 | val loss 0.4460 | acc 0.8312 | f1 0.8261 | prec 0.8515 | recall 0.8022 | roc auc 0.9035 | pr auc 0.9194 | elapsed 4.36s\n",
      "train epoch 14/15 | batch 132/131 | loss 0.1800 | val loss 0.4346 | acc 0.8372 | f1 0.8332 | prec 0.8541 | recall 0.8133 | roc auc 0.9076 | pr auc 0.9227 | elapsed 4.33s\n",
      "train epoch 15/15 | batch 132/131 | loss 0.1646 | val loss 0.4250 | acc 0.8394 | f1 0.8362 | prec 0.8530 | recall 0.8201 | roc auc 0.9111 | pr auc 0.9254 | elapsed 4.43s\n",
      "Complexity threshold 9\n",
      "Training 17546 #pos 8773\n",
      "Validation 4368 #pos 2184\n",
      "Test 17888 #pos 17888\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 139/138 | loss 1.2455 | val loss 1.2438 | acc 0.6557 | f1 0.5924 | prec 0.7258 | recall 0.5005 | roc auc 0.6831 | pr auc 0.7507 | elapsed 1.87s\n",
      "train epoch 01/15 | batch 139/138 | loss 1.1752 | val loss 1.0961 | acc 0.6758 | f1 0.6210 | prec 0.7474 | recall 0.5311 | roc auc 0.7176 | pr auc 0.7747 | elapsed 4.60s\n",
      "train epoch 02/15 | batch 139/138 | loss 0.9865 | val loss 0.9612 | acc 0.6980 | f1 0.6521 | prec 0.7691 | recall 0.5659 | roc auc 0.7509 | pr auc 0.7987 | elapsed 4.80s\n",
      "train epoch 03/15 | batch 139/138 | loss 0.8297 | val loss 0.8464 | acc 0.7191 | f1 0.6812 | prec 0.7874 | recall 0.6003 | roc auc 0.7813 | pr auc 0.8210 | elapsed 4.82s\n",
      "train epoch 04/15 | batch 139/138 | loss 0.6892 | val loss 0.7493 | acc 0.7404 | f1 0.7106 | prec 0.8028 | recall 0.6374 | roc auc 0.8086 | pr auc 0.8418 | elapsed 4.24s\n",
      "train epoch 05/15 | batch 139/138 | loss 0.5772 | val loss 0.6707 | acc 0.7571 | f1 0.7331 | prec 0.8135 | recall 0.6671 | roc auc 0.8319 | pr auc 0.8597 | elapsed 4.57s\n",
      "train epoch 06/15 | batch 139/138 | loss 0.4886 | val loss 0.6074 | acc 0.7763 | f1 0.7570 | prec 0.8285 | recall 0.6969 | roc auc 0.8513 | pr auc 0.8749 | elapsed 4.92s\n",
      "train epoch 07/15 | batch 139/138 | loss 0.4154 | val loss 0.5566 | acc 0.7885 | f1 0.7733 | prec 0.8330 | recall 0.7216 | roc auc 0.8673 | pr auc 0.8877 | elapsed 4.59s\n",
      "train epoch 08/15 | batch 139/138 | loss 0.3546 | val loss 0.5162 | acc 0.8045 | f1 0.7931 | prec 0.8421 | recall 0.7495 | roc auc 0.8802 | pr auc 0.8980 | elapsed 4.26s\n",
      "train epoch 09/15 | batch 139/138 | loss 0.3122 | val loss 0.4845 | acc 0.8141 | f1 0.8052 | prec 0.8458 | recall 0.7683 | roc auc 0.8906 | pr auc 0.9064 | elapsed 4.41s\n",
      "train epoch 10/15 | batch 139/138 | loss 0.2734 | val loss 0.4592 | acc 0.8217 | f1 0.8145 | prec 0.8486 | recall 0.7830 | roc auc 0.8990 | pr auc 0.9134 | elapsed 4.46s\n",
      "train epoch 11/15 | batch 139/138 | loss 0.2409 | val loss 0.4388 | acc 0.8304 | f1 0.8246 | prec 0.8535 | recall 0.7976 | roc auc 0.9060 | pr auc 0.9191 | elapsed 4.53s\n",
      "train epoch 12/15 | batch 139/138 | loss 0.2151 | val loss 0.4225 | acc 0.8370 | f1 0.8322 | prec 0.8573 | recall 0.8086 | roc auc 0.9115 | pr auc 0.9237 | elapsed 4.84s\n",
      "train epoch 13/15 | batch 139/138 | loss 0.1937 | val loss 0.4095 | acc 0.8429 | f1 0.8394 | prec 0.8587 | recall 0.8210 | roc auc 0.9161 | pr auc 0.9275 | elapsed 4.49s\n",
      "train epoch 14/15 | batch 139/138 | loss 0.1777 | val loss 0.3989 | acc 0.8480 | f1 0.8454 | prec 0.8602 | recall 0.8310 | roc auc 0.9197 | pr auc 0.9306 | elapsed 4.86s\n",
      "train epoch 15/15 | batch 139/138 | loss 0.1605 | val loss 0.3900 | acc 0.8512 | f1 0.8490 | prec 0.8618 | recall 0.8365 | roc auc 0.9229 | pr auc 0.9333 | elapsed 4.48s\n",
      "Complexity threshold 10\n",
      "Training 18428 #pos 9214\n",
      "Validation 4584 #pos 2292\n",
      "Test 17339 #pos 17339\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 145/144 | loss 1.2850 | val loss 1.2933 | acc 0.6396 | f1 0.5781 | prec 0.6970 | recall 0.4939 | roc auc 0.6660 | pr auc 0.7388 | elapsed 1.95s\n",
      "train epoch 01/15 | batch 145/144 | loss 1.2017 | val loss 1.1250 | acc 0.6625 | f1 0.6079 | prec 0.7253 | recall 0.5231 | roc auc 0.7046 | pr auc 0.7645 | elapsed 4.56s\n",
      "train epoch 02/15 | batch 145/144 | loss 1.0013 | val loss 0.9729 | acc 0.6865 | f1 0.6396 | prec 0.7522 | recall 0.5563 | roc auc 0.7424 | pr auc 0.7910 | elapsed 4.77s\n",
      "train epoch 03/15 | batch 145/144 | loss 0.8280 | val loss 0.8438 | acc 0.7116 | f1 0.6739 | prec 0.7753 | recall 0.5960 | roc auc 0.7771 | pr auc 0.8164 | elapsed 5.75s\n",
      "train epoch 04/15 | batch 145/144 | loss 0.6840 | val loss 0.7380 | acc 0.7343 | f1 0.7054 | prec 0.7915 | recall 0.6361 | roc auc 0.8077 | pr auc 0.8397 | elapsed 6.11s\n",
      "train epoch 05/15 | batch 145/144 | loss 0.5677 | val loss 0.6527 | acc 0.7594 | f1 0.7384 | prec 0.8088 | recall 0.6793 | roc auc 0.8335 | pr auc 0.8598 | elapsed 5.15s\n",
      "train epoch 06/15 | batch 145/144 | loss 0.4753 | val loss 0.5860 | acc 0.7760 | f1 0.7606 | prec 0.8167 | recall 0.7116 | roc auc 0.8545 | pr auc 0.8768 | elapsed 5.11s\n",
      "train epoch 07/15 | batch 145/144 | loss 0.4025 | val loss 0.5328 | acc 0.7936 | f1 0.7830 | prec 0.8254 | recall 0.7448 | roc auc 0.8718 | pr auc 0.8907 | elapsed 5.18s\n",
      "train epoch 08/15 | batch 145/144 | loss 0.3452 | val loss 0.4907 | acc 0.8089 | f1 0.8011 | prec 0.8352 | recall 0.7696 | roc auc 0.8857 | pr auc 0.9021 | elapsed 4.92s\n",
      "train epoch 09/15 | batch 145/144 | loss 0.2996 | val loss 0.4580 | acc 0.8209 | f1 0.8150 | prec 0.8426 | recall 0.7893 | roc auc 0.8966 | pr auc 0.9111 | elapsed 5.05s\n",
      "train epoch 10/15 | batch 145/144 | loss 0.2630 | val loss 0.4317 | acc 0.8312 | f1 0.8268 | prec 0.8488 | recall 0.8058 | roc auc 0.9056 | pr auc 0.9184 | elapsed 4.76s\n",
      "train epoch 11/15 | batch 145/144 | loss 0.2333 | val loss 0.4107 | acc 0.8401 | f1 0.8369 | prec 0.8542 | recall 0.8202 | roc auc 0.9129 | pr auc 0.9245 | elapsed 4.65s\n",
      "train epoch 12/15 | batch 145/144 | loss 0.2090 | val loss 0.3937 | acc 0.8464 | f1 0.8440 | prec 0.8577 | recall 0.8307 | roc auc 0.9187 | pr auc 0.9293 | elapsed 4.57s\n",
      "train epoch 13/15 | batch 145/144 | loss 0.1886 | val loss 0.3802 | acc 0.8538 | f1 0.8519 | prec 0.8634 | recall 0.8408 | roc auc 0.9234 | pr auc 0.9333 | elapsed 4.90s\n",
      "train epoch 14/15 | batch 145/144 | loss 0.1715 | val loss 0.3686 | acc 0.8575 | f1 0.8559 | prec 0.8660 | recall 0.8460 | roc auc 0.9274 | pr auc 0.9365 | elapsed 4.58s\n",
      "train epoch 15/15 | batch 145/144 | loss 0.1567 | val loss 0.3590 | acc 0.8619 | f1 0.8604 | prec 0.8698 | recall 0.8512 | roc auc 0.9307 | pr auc 0.9393 | elapsed 4.97s\n",
      "Complexity threshold 11\n",
      "Training 19454 #pos 9727\n",
      "Validation 4844 #pos 2422\n",
      "Test 16696 #pos 16696\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 153/152 | loss 1.2930 | val loss 1.2763 | acc 0.6416 | f1 0.5737 | prec 0.7079 | recall 0.4822 | roc auc 0.6696 | pr auc 0.7387 | elapsed 2.27s\n",
      "train epoch 01/15 | batch 153/152 | loss 1.2035 | val loss 1.0974 | acc 0.6689 | f1 0.6120 | prec 0.7389 | recall 0.5223 | roc auc 0.7122 | pr auc 0.7682 | elapsed 4.99s\n",
      "train epoch 02/15 | batch 153/152 | loss 0.9915 | val loss 0.9378 | acc 0.6947 | f1 0.6478 | prec 0.7653 | recall 0.5615 | roc auc 0.7532 | pr auc 0.7977 | elapsed 5.52s\n",
      "train epoch 03/15 | batch 153/152 | loss 0.8092 | val loss 0.8043 | acc 0.7221 | f1 0.6865 | prec 0.7874 | recall 0.6086 | roc auc 0.7901 | pr auc 0.8254 | elapsed 4.93s\n",
      "train epoch 04/15 | batch 153/152 | loss 0.6598 | val loss 0.6974 | acc 0.7444 | f1 0.7175 | prec 0.8020 | recall 0.6491 | roc auc 0.8216 | pr auc 0.8497 | elapsed 5.20s\n",
      "train epoch 05/15 | batch 153/152 | loss 0.5412 | val loss 0.6147 | acc 0.7673 | f1 0.7483 | prec 0.8151 | recall 0.6916 | roc auc 0.8472 | pr auc 0.8701 | elapsed 4.86s\n",
      "train epoch 06/15 | batch 153/152 | loss 0.4489 | val loss 0.5512 | acc 0.7867 | f1 0.7729 | prec 0.8265 | recall 0.7258 | roc auc 0.8676 | pr auc 0.8864 | elapsed 5.14s\n",
      "train epoch 07/15 | batch 153/152 | loss 0.3777 | val loss 0.5024 | acc 0.8031 | f1 0.7937 | prec 0.8333 | recall 0.7576 | roc auc 0.8835 | pr auc 0.8993 | elapsed 5.10s\n",
      "train epoch 08/15 | batch 153/152 | loss 0.3225 | val loss 0.4650 | acc 0.8169 | f1 0.8103 | prec 0.8404 | recall 0.7824 | roc auc 0.8960 | pr auc 0.9095 | elapsed 5.12s\n",
      "train epoch 09/15 | batch 153/152 | loss 0.2793 | val loss 0.4366 | acc 0.8284 | f1 0.8239 | prec 0.8463 | recall 0.8026 | roc auc 0.9057 | pr auc 0.9174 | elapsed 5.00s\n",
      "train epoch 10/15 | batch 153/152 | loss 0.2448 | val loss 0.4139 | acc 0.8396 | f1 0.8365 | prec 0.8529 | recall 0.8208 | roc auc 0.9135 | pr auc 0.9237 | elapsed 5.53s\n",
      "train epoch 11/15 | batch 153/152 | loss 0.2172 | val loss 0.3964 | acc 0.8483 | f1 0.8459 | prec 0.8591 | recall 0.8332 | roc auc 0.9195 | pr auc 0.9286 | elapsed 6.53s\n",
      "train epoch 12/15 | batch 153/152 | loss 0.1945 | val loss 0.3824 | acc 0.8549 | f1 0.8531 | prec 0.8637 | recall 0.8427 | roc auc 0.9245 | pr auc 0.9327 | elapsed 6.13s\n",
      "train epoch 13/15 | batch 153/152 | loss 0.1756 | val loss 0.3710 | acc 0.8594 | f1 0.8584 | prec 0.8647 | recall 0.8522 | roc auc 0.9284 | pr auc 0.9360 | elapsed 5.10s\n",
      "train epoch 14/15 | batch 153/152 | loss 0.1597 | val loss 0.3616 | acc 0.8625 | f1 0.8615 | prec 0.8680 | recall 0.8551 | roc auc 0.9318 | pr auc 0.9387 | elapsed 5.09s\n",
      "train epoch 15/15 | batch 153/152 | loss 0.1461 | val loss 0.3538 | acc 0.8658 | f1 0.8650 | prec 0.8704 | recall 0.8596 | roc auc 0.9346 | pr auc 0.9410 | elapsed 5.13s\n",
      "Complexity threshold 12\n",
      "Training 20449 #pos 10229\n",
      "Validation 5092 #pos 2547\n",
      "Test 16069 #pos 16069\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 161/160 | loss 1.3386 | val loss 1.3232 | acc 0.6210 | f1 0.5431 | prec 0.6840 | recall 0.4503 | roc auc 0.6537 | pr auc 0.7177 | elapsed 2.10s\n",
      "train epoch 01/15 | batch 161/160 | loss 1.2396 | val loss 1.1183 | acc 0.6516 | f1 0.5871 | prec 0.7210 | recall 0.4951 | roc auc 0.7029 | pr auc 0.7518 | elapsed 5.56s\n",
      "train epoch 02/15 | batch 161/160 | loss 1.0116 | val loss 0.9401 | acc 0.6807 | f1 0.6301 | prec 0.7491 | recall 0.5438 | roc auc 0.7491 | pr auc 0.7861 | elapsed 6.30s\n",
      "train epoch 03/15 | batch 161/160 | loss 0.8157 | val loss 0.7922 | acc 0.7150 | f1 0.6772 | prec 0.7813 | recall 0.5976 | roc auc 0.7907 | pr auc 0.8187 | elapsed 7.68s\n",
      "train epoch 04/15 | batch 161/160 | loss 0.6584 | val loss 0.6772 | acc 0.7455 | f1 0.7190 | prec 0.8029 | recall 0.6510 | roc auc 0.8256 | pr auc 0.8471 | elapsed 5.48s\n",
      "train epoch 05/15 | batch 161/160 | loss 0.5352 | val loss 0.5915 | acc 0.7720 | f1 0.7552 | prec 0.8156 | recall 0.7032 | roc auc 0.8529 | pr auc 0.8700 | elapsed 5.60s\n",
      "train epoch 06/15 | batch 161/160 | loss 0.4419 | val loss 0.5276 | acc 0.7936 | f1 0.7815 | prec 0.8304 | recall 0.7381 | roc auc 0.8739 | pr auc 0.8879 | elapsed 5.72s\n",
      "train epoch 07/15 | batch 161/160 | loss 0.3704 | val loss 0.4797 | acc 0.8085 | f1 0.7999 | prec 0.8379 | recall 0.7652 | roc auc 0.8900 | pr auc 0.9018 | elapsed 5.26s\n",
      "train epoch 08/15 | batch 161/160 | loss 0.3156 | val loss 0.4437 | acc 0.8231 | f1 0.8167 | prec 0.8476 | recall 0.7880 | roc auc 0.9022 | pr auc 0.9126 | elapsed 5.75s\n",
      "train epoch 09/15 | batch 161/160 | loss 0.2726 | val loss 0.4166 | acc 0.8348 | f1 0.8311 | prec 0.8507 | recall 0.8123 | roc auc 0.9114 | pr auc 0.9208 | elapsed 5.55s\n",
      "train epoch 10/15 | batch 161/160 | loss 0.2388 | val loss 0.3956 | acc 0.8435 | f1 0.8411 | prec 0.8545 | recall 0.8280 | roc auc 0.9187 | pr auc 0.9272 | elapsed 5.00s\n",
      "train epoch 11/15 | batch 161/160 | loss 0.2117 | val loss 0.3793 | acc 0.8492 | f1 0.8476 | prec 0.8568 | recall 0.8386 | roc auc 0.9244 | pr auc 0.9322 | elapsed 4.90s\n",
      "train epoch 12/15 | batch 161/160 | loss 0.1896 | val loss 0.3669 | acc 0.8560 | f1 0.8552 | prec 0.8608 | recall 0.8496 | roc auc 0.9289 | pr auc 0.9361 | elapsed 5.18s\n",
      "train epoch 13/15 | batch 161/160 | loss 0.1710 | val loss 0.3565 | acc 0.8604 | f1 0.8602 | prec 0.8614 | recall 0.8590 | roc auc 0.9326 | pr auc 0.9394 | elapsed 5.22s\n",
      "train epoch 14/15 | batch 161/160 | loss 0.1556 | val loss 0.3482 | acc 0.8639 | f1 0.8640 | prec 0.8635 | recall 0.8645 | roc auc 0.9356 | pr auc 0.9421 | elapsed 5.17s\n",
      "train epoch 15/15 | batch 161/160 | loss 0.1422 | val loss 0.3416 | acc 0.8674 | f1 0.8677 | prec 0.8662 | recall 0.8693 | roc auc 0.9381 | pr auc 0.9442 | elapsed 5.04s\n",
      "Complexity threshold 13\n",
      "Training 21712 #pos 10868\n",
      "Validation 5408 #pos 2707\n",
      "Test 15270 #pos 15270\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 171/170 | loss 1.3366 | val loss 1.3750 | acc 0.6195 | f1 0.5386 | prec 0.6851 | recall 0.4437 | roc auc 0.6405 | pr auc 0.7098 | elapsed 2.29s\n",
      "train epoch 01/15 | batch 171/170 | loss 1.2282 | val loss 1.1520 | acc 0.6527 | f1 0.5883 | prec 0.7235 | recall 0.4958 | roc auc 0.6935 | pr auc 0.7484 | elapsed 5.12s\n",
      "train epoch 02/15 | batch 171/170 | loss 0.9843 | val loss 0.9587 | acc 0.6886 | f1 0.6391 | prec 0.7611 | recall 0.5508 | roc auc 0.7435 | pr auc 0.7867 | elapsed 5.02s\n",
      "train epoch 03/15 | batch 171/170 | loss 0.7807 | val loss 0.8022 | acc 0.7249 | f1 0.6903 | prec 0.7907 | recall 0.6125 | roc auc 0.7879 | pr auc 0.8218 | elapsed 5.20s\n",
      "train epoch 04/15 | batch 171/170 | loss 0.6205 | val loss 0.6823 | acc 0.7578 | f1 0.7328 | prec 0.8182 | recall 0.6635 | roc auc 0.8242 | pr auc 0.8512 | elapsed 4.94s\n",
      "train epoch 05/15 | batch 171/170 | loss 0.4991 | val loss 0.5929 | acc 0.7818 | f1 0.7642 | prec 0.8324 | recall 0.7063 | roc auc 0.8526 | pr auc 0.8744 | elapsed 5.17s\n",
      "train epoch 06/15 | batch 171/170 | loss 0.4090 | val loss 0.5255 | acc 0.8027 | f1 0.7905 | prec 0.8437 | recall 0.7436 | roc auc 0.8747 | pr auc 0.8927 | elapsed 5.33s\n",
      "train epoch 07/15 | batch 171/170 | loss 0.3410 | val loss 0.4764 | acc 0.8197 | f1 0.8107 | prec 0.8543 | recall 0.7713 | roc auc 0.8911 | pr auc 0.9063 | elapsed 5.34s\n",
      "train epoch 08/15 | batch 171/170 | loss 0.2898 | val loss 0.4397 | acc 0.8327 | f1 0.8259 | prec 0.8618 | recall 0.7928 | roc auc 0.9034 | pr auc 0.9165 | elapsed 5.38s\n",
      "train epoch 09/15 | batch 171/170 | loss 0.2504 | val loss 0.4118 | acc 0.8404 | f1 0.8355 | prec 0.8633 | recall 0.8094 | roc auc 0.9128 | pr auc 0.9245 | elapsed 5.68s\n",
      "train epoch 10/15 | batch 171/170 | loss 0.2189 | val loss 0.3908 | acc 0.8515 | f1 0.8478 | prec 0.8704 | recall 0.8264 | roc auc 0.9200 | pr auc 0.9306 | elapsed 5.57s\n",
      "train epoch 11/15 | batch 171/170 | loss 0.1940 | val loss 0.3746 | acc 0.8598 | f1 0.8574 | prec 0.8735 | recall 0.8419 | roc auc 0.9256 | pr auc 0.9353 | elapsed 5.76s\n",
      "train epoch 12/15 | batch 171/170 | loss 0.1738 | val loss 0.3620 | acc 0.8650 | f1 0.8631 | prec 0.8763 | recall 0.8504 | roc auc 0.9300 | pr auc 0.9391 | elapsed 5.82s\n",
      "train epoch 13/15 | batch 171/170 | loss 0.1567 | val loss 0.3518 | acc 0.8693 | f1 0.8680 | prec 0.8776 | recall 0.8585 | roc auc 0.9336 | pr auc 0.9421 | elapsed 5.35s\n",
      "train epoch 14/15 | batch 171/170 | loss 0.1426 | val loss 0.3436 | acc 0.8724 | f1 0.8715 | prec 0.8790 | recall 0.8641 | roc auc 0.9365 | pr auc 0.9445 | elapsed 5.43s\n",
      "train epoch 15/15 | batch 171/170 | loss 0.1305 | val loss 0.3373 | acc 0.8746 | f1 0.8736 | prec 0.8815 | recall 0.8659 | roc auc 0.9388 | pr auc 0.9464 | elapsed 5.23s\n",
      "Complexity threshold 14\n",
      "Training 22743 #pos 11460\n",
      "Validation 5664 #pos 2854\n",
      "Test 14531 #pos 14531\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 179/178 | loss 1.3710 | val loss 1.3828 | acc 0.6156 | f1 0.5273 | prec 0.6933 | recall 0.4254 | roc auc 0.6402 | pr auc 0.7079 | elapsed 2.62s\n",
      "train epoch 01/15 | batch 179/178 | loss 1.2525 | val loss 1.1384 | acc 0.6511 | f1 0.5817 | prec 0.7348 | recall 0.4814 | roc auc 0.6994 | pr auc 0.7505 | elapsed 6.44s\n",
      "train epoch 02/15 | batch 179/178 | loss 0.9881 | val loss 0.9271 | acc 0.6910 | f1 0.6401 | prec 0.7749 | recall 0.5452 | roc auc 0.7550 | pr auc 0.7936 | elapsed 5.17s\n",
      "train epoch 03/15 | batch 179/178 | loss 0.7711 | val loss 0.7628 | acc 0.7331 | f1 0.7009 | prec 0.8047 | recall 0.6209 | roc auc 0.8019 | pr auc 0.8323 | elapsed 5.12s\n",
      "train epoch 04/15 | batch 179/178 | loss 0.6033 | val loss 0.6415 | acc 0.7692 | f1 0.7505 | prec 0.8243 | recall 0.6889 | roc auc 0.8389 | pr auc 0.8636 | elapsed 5.37s\n",
      "train epoch 05/15 | batch 179/178 | loss 0.4801 | val loss 0.5533 | acc 0.7948 | f1 0.7828 | prec 0.8389 | recall 0.7337 | roc auc 0.8668 | pr auc 0.8873 | elapsed 5.12s\n",
      "train epoch 06/15 | batch 179/178 | loss 0.3895 | val loss 0.4899 | acc 0.8176 | f1 0.8092 | prec 0.8555 | recall 0.7677 | roc auc 0.8875 | pr auc 0.9045 | elapsed 5.46s\n",
      "train epoch 07/15 | batch 179/178 | loss 0.3241 | val loss 0.4427 | acc 0.8342 | f1 0.8285 | prec 0.8653 | recall 0.7947 | roc auc 0.9031 | pr auc 0.9174 | elapsed 5.17s\n",
      "train epoch 08/15 | batch 179/178 | loss 0.2747 | val loss 0.4077 | acc 0.8464 | f1 0.8424 | prec 0.8721 | recall 0.8146 | roc auc 0.9148 | pr auc 0.9271 | elapsed 5.32s\n",
      "train epoch 09/15 | batch 179/178 | loss 0.2375 | val loss 0.3809 | acc 0.8566 | f1 0.8540 | prec 0.8770 | recall 0.8322 | roc auc 0.9237 | pr auc 0.9345 | elapsed 5.26s\n",
      "train epoch 10/15 | batch 179/178 | loss 0.2085 | val loss 0.3599 | acc 0.8621 | f1 0.8601 | prec 0.8798 | recall 0.8413 | roc auc 0.9307 | pr auc 0.9402 | elapsed 5.23s\n",
      "train epoch 11/15 | batch 179/178 | loss 0.1851 | val loss 0.3434 | acc 0.8694 | f1 0.8682 | prec 0.8830 | recall 0.8539 | roc auc 0.9361 | pr auc 0.9448 | elapsed 5.09s\n",
      "train epoch 12/15 | batch 179/178 | loss 0.1661 | val loss 0.3303 | acc 0.8734 | f1 0.8727 | prec 0.8845 | recall 0.8612 | roc auc 0.9403 | pr auc 0.9484 | elapsed 5.59s\n",
      "train epoch 13/15 | batch 179/178 | loss 0.1504 | val loss 0.3197 | acc 0.8775 | f1 0.8772 | prec 0.8863 | recall 0.8683 | roc auc 0.9438 | pr auc 0.9514 | elapsed 5.64s\n",
      "train epoch 14/15 | batch 179/178 | loss 0.1368 | val loss 0.3111 | acc 0.8821 | f1 0.8822 | prec 0.8879 | recall 0.8767 | roc auc 0.9465 | pr auc 0.9538 | elapsed 5.56s\n",
      "train epoch 15/15 | batch 179/178 | loss 0.1254 | val loss 0.3041 | acc 0.8854 | f1 0.8859 | prec 0.8892 | recall 0.8826 | roc auc 0.9488 | pr auc 0.9557 | elapsed 5.64s\n",
      "Complexity threshold 15\n",
      "Training 23756 #pos 12146\n",
      "Validation 5920 #pos 3027\n",
      "Test 13672 #pos 13672\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 187/186 | loss 1.4145 | val loss 1.3555 | acc 0.6194 | f1 0.5407 | prec 0.7061 | recall 0.4381 | roc auc 0.6460 | pr auc 0.7195 | elapsed 2.52s\n",
      "train epoch 01/15 | batch 187/186 | loss 1.2804 | val loss 1.0930 | acc 0.6569 | f1 0.5973 | prec 0.7470 | recall 0.4975 | roc auc 0.7102 | pr auc 0.7656 | elapsed 6.40s\n",
      "train epoch 02/15 | batch 187/186 | loss 0.9937 | val loss 0.8734 | acc 0.7003 | f1 0.6595 | prec 0.7870 | recall 0.5676 | roc auc 0.7695 | pr auc 0.8108 | elapsed 6.12s\n",
      "train epoch 03/15 | batch 187/186 | loss 0.7628 | val loss 0.7065 | acc 0.7463 | f1 0.7234 | prec 0.8173 | recall 0.6488 | roc auc 0.8186 | pr auc 0.8499 | elapsed 6.24s\n",
      "train epoch 04/15 | batch 187/186 | loss 0.5908 | val loss 0.5874 | acc 0.7828 | f1 0.7695 | prec 0.8410 | recall 0.7093 | roc auc 0.8559 | pr auc 0.8802 | elapsed 6.38s\n",
      "train epoch 05/15 | batch 187/186 | loss 0.4676 | val loss 0.5044 | acc 0.8073 | f1 0.7995 | prec 0.8540 | recall 0.7516 | roc auc 0.8828 | pr auc 0.9022 | elapsed 5.65s\n",
      "train epoch 06/15 | batch 187/186 | loss 0.3789 | val loss 0.4463 | acc 0.8280 | f1 0.8245 | prec 0.8620 | recall 0.7902 | roc auc 0.9019 | pr auc 0.9178 | elapsed 5.78s\n",
      "train epoch 07/15 | batch 187/186 | loss 0.3142 | val loss 0.4051 | acc 0.8478 | f1 0.8474 | prec 0.8696 | recall 0.8262 | roc auc 0.9155 | pr auc 0.9290 | elapsed 5.49s\n",
      "train epoch 08/15 | batch 187/186 | loss 0.2663 | val loss 0.3760 | acc 0.8581 | f1 0.8589 | prec 0.8738 | recall 0.8444 | roc auc 0.9251 | pr auc 0.9369 | elapsed 5.61s\n",
      "train epoch 09/15 | batch 187/186 | loss 0.2298 | val loss 0.3540 | acc 0.8676 | f1 0.8692 | prec 0.8777 | recall 0.8609 | roc auc 0.9324 | pr auc 0.9430 | elapsed 5.68s\n",
      "train epoch 10/15 | batch 187/186 | loss 0.2016 | val loss 0.3380 | acc 0.8728 | f1 0.8750 | prec 0.8793 | recall 0.8708 | roc auc 0.9377 | pr auc 0.9474 | elapsed 5.62s\n",
      "train epoch 11/15 | batch 187/186 | loss 0.1791 | val loss 0.3259 | acc 0.8780 | f1 0.8804 | prec 0.8828 | recall 0.8781 | roc auc 0.9418 | pr auc 0.9508 | elapsed 5.65s\n",
      "train epoch 12/15 | batch 187/186 | loss 0.1607 | val loss 0.3160 | acc 0.8838 | f1 0.8865 | prec 0.8856 | recall 0.8873 | roc auc 0.9451 | pr auc 0.9535 | elapsed 5.58s\n",
      "train epoch 13/15 | batch 187/186 | loss 0.1454 | val loss 0.3084 | acc 0.8880 | f1 0.8909 | prec 0.8878 | recall 0.8940 | roc auc 0.9476 | pr auc 0.9556 | elapsed 5.47s\n",
      "train epoch 14/15 | batch 187/186 | loss 0.1325 | val loss 0.3023 | acc 0.8902 | f1 0.8931 | prec 0.8890 | recall 0.8973 | roc auc 0.9497 | pr auc 0.9574 | elapsed 5.63s\n",
      "train epoch 15/15 | batch 187/186 | loss 0.1214 | val loss 0.2973 | acc 0.8914 | f1 0.8943 | prec 0.8901 | recall 0.8986 | roc auc 0.9514 | pr auc 0.9588 | elapsed 5.62s\n",
      "Complexity threshold 16\n",
      "Training 24695 #pos 12803\n",
      "Validation 6152 #pos 3190\n",
      "Test 12852 #pos 12852\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 194/193 | loss 1.4494 | val loss 1.4958 | acc 0.5923 | f1 0.4994 | prec 0.6874 | recall 0.3922 | roc auc 0.6157 | pr auc 0.6969 | elapsed 2.40s\n",
      "train epoch 01/15 | batch 194/193 | loss 1.3040 | val loss 1.1952 | acc 0.6318 | f1 0.5613 | prec 0.7344 | recall 0.4542 | roc auc 0.6859 | pr auc 0.7467 | elapsed 5.78s\n",
      "train epoch 02/15 | batch 194/193 | loss 0.9941 | val loss 0.9393 | acc 0.6817 | f1 0.6362 | prec 0.7810 | recall 0.5367 | roc auc 0.7525 | pr auc 0.7975 | elapsed 6.09s\n",
      "train epoch 03/15 | batch 194/193 | loss 0.7474 | val loss 0.7472 | acc 0.7264 | f1 0.6992 | prec 0.8133 | recall 0.6132 | roc auc 0.8075 | pr auc 0.8416 | elapsed 5.84s\n",
      "train epoch 04/15 | batch 194/193 | loss 0.5690 | val loss 0.6130 | acc 0.7689 | f1 0.7548 | prec 0.8387 | recall 0.6862 | roc auc 0.8485 | pr auc 0.8754 | elapsed 5.90s\n",
      "train epoch 05/15 | batch 194/193 | loss 0.4455 | val loss 0.5210 | acc 0.8020 | f1 0.7958 | prec 0.8552 | recall 0.7442 | roc auc 0.8779 | pr auc 0.8995 | elapsed 5.85s\n",
      "train epoch 06/15 | batch 194/193 | loss 0.3594 | val loss 0.4569 | acc 0.8231 | f1 0.8203 | prec 0.8667 | recall 0.7787 | roc auc 0.8988 | pr auc 0.9164 | elapsed 5.89s\n",
      "train epoch 07/15 | batch 194/193 | loss 0.2978 | val loss 0.4118 | acc 0.8405 | f1 0.8401 | prec 0.8748 | recall 0.8082 | roc auc 0.9136 | pr auc 0.9284 | elapsed 6.10s\n",
      "train epoch 08/15 | batch 194/193 | loss 0.2524 | val loss 0.3791 | acc 0.8566 | f1 0.8576 | prec 0.8842 | recall 0.8326 | roc auc 0.9243 | pr auc 0.9370 | elapsed 6.44s\n",
      "train epoch 09/15 | batch 194/193 | loss 0.2180 | val loss 0.3545 | acc 0.8665 | f1 0.8683 | prec 0.8890 | recall 0.8486 | roc auc 0.9323 | pr auc 0.9434 | elapsed 6.74s\n",
      "train epoch 10/15 | batch 194/193 | loss 0.1912 | val loss 0.3359 | acc 0.8763 | f1 0.8785 | prec 0.8952 | recall 0.8624 | roc auc 0.9383 | pr auc 0.9483 | elapsed 6.02s\n",
      "train epoch 11/15 | batch 194/193 | loss 0.1697 | val loss 0.3221 | acc 0.8817 | f1 0.8842 | prec 0.8974 | recall 0.8715 | roc auc 0.9427 | pr auc 0.9519 | elapsed 6.38s\n",
      "train epoch 12/15 | batch 194/193 | loss 0.1522 | val loss 0.3114 | acc 0.8854 | f1 0.8882 | prec 0.8986 | recall 0.8781 | roc auc 0.9461 | pr auc 0.9548 | elapsed 6.49s\n",
      "train epoch 13/15 | batch 194/193 | loss 0.1376 | val loss 0.3030 | acc 0.8893 | f1 0.8923 | prec 0.9002 | recall 0.8846 | roc auc 0.9488 | pr auc 0.9570 | elapsed 6.94s\n",
      "train epoch 14/15 | batch 194/193 | loss 0.1253 | val loss 0.2964 | acc 0.8919 | f1 0.8952 | prec 0.9004 | recall 0.8900 | roc auc 0.9510 | pr auc 0.9588 | elapsed 6.41s\n",
      "train epoch 15/15 | batch 194/193 | loss 0.1146 | val loss 0.2909 | acc 0.8942 | f1 0.8974 | prec 0.9021 | recall 0.8928 | roc auc 0.9528 | pr auc 0.9604 | elapsed 6.33s\n",
      "Complexity threshold 17\n",
      "Training 25812 #pos 13581\n",
      "Validation 6437 #pos 3388\n",
      "Test 11876 #pos 11876\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 203/202 | loss 1.5053 | val loss 1.4996 | acc 0.5847 | f1 0.4988 | prec 0.6838 | recall 0.3926 | roc auc 0.6181 | pr auc 0.6995 | elapsed 2.87s\n",
      "train epoch 01/15 | batch 203/202 | loss 1.3397 | val loss 1.1717 | acc 0.6300 | f1 0.5697 | prec 0.7342 | recall 0.4655 | roc auc 0.6933 | pr auc 0.7535 | elapsed 6.65s\n",
      "train epoch 02/15 | batch 203/202 | loss 0.9988 | val loss 0.9008 | acc 0.6843 | f1 0.6499 | prec 0.7806 | recall 0.5567 | roc auc 0.7632 | pr auc 0.8080 | elapsed 6.47s\n",
      "train epoch 03/15 | batch 203/202 | loss 0.7329 | val loss 0.7050 | acc 0.7399 | f1 0.7263 | prec 0.8141 | recall 0.6555 | roc auc 0.8196 | pr auc 0.8542 | elapsed 6.76s\n",
      "train epoch 04/15 | batch 203/202 | loss 0.5482 | val loss 0.5760 | acc 0.7851 | f1 0.7806 | prec 0.8439 | recall 0.7261 | roc auc 0.8597 | pr auc 0.8875 | elapsed 7.37s\n",
      "train epoch 05/15 | batch 203/202 | loss 0.4254 | val loss 0.4915 | acc 0.8173 | f1 0.8178 | prec 0.8607 | recall 0.7789 | roc auc 0.8868 | pr auc 0.9100 | elapsed 6.96s\n",
      "train epoch 06/15 | batch 203/202 | loss 0.3424 | val loss 0.4348 | acc 0.8395 | f1 0.8421 | prec 0.8732 | recall 0.8132 | roc auc 0.9053 | pr auc 0.9251 | elapsed 7.35s\n",
      "train epoch 07/15 | batch 203/202 | loss 0.2837 | val loss 0.3951 | acc 0.8543 | f1 0.8581 | prec 0.8800 | recall 0.8374 | roc auc 0.9183 | pr auc 0.9355 | elapsed 6.31s\n",
      "train epoch 08/15 | batch 203/202 | loss 0.2411 | val loss 0.3666 | acc 0.8647 | f1 0.8694 | prec 0.8836 | recall 0.8557 | roc auc 0.9275 | pr auc 0.9429 | elapsed 6.34s\n",
      "train epoch 09/15 | batch 203/202 | loss 0.2087 | val loss 0.3456 | acc 0.8734 | f1 0.8785 | prec 0.8876 | recall 0.8695 | roc auc 0.9343 | pr auc 0.9483 | elapsed 5.93s\n",
      "train epoch 10/15 | batch 203/202 | loss 0.1836 | val loss 0.3294 | acc 0.8793 | f1 0.8845 | prec 0.8908 | recall 0.8784 | roc auc 0.9396 | pr auc 0.9524 | elapsed 5.98s\n",
      "train epoch 11/15 | batch 203/202 | loss 0.1635 | val loss 0.3169 | acc 0.8841 | f1 0.8894 | prec 0.8936 | recall 0.8852 | roc auc 0.9437 | pr auc 0.9555 | elapsed 6.55s\n",
      "train epoch 12/15 | batch 203/202 | loss 0.1468 | val loss 0.3073 | acc 0.8871 | f1 0.8924 | prec 0.8949 | recall 0.8899 | roc auc 0.9469 | pr auc 0.9580 | elapsed 6.82s\n",
      "train epoch 13/15 | batch 203/202 | loss 0.1332 | val loss 0.2996 | acc 0.8913 | f1 0.8964 | prec 0.8986 | recall 0.8943 | roc auc 0.9495 | pr auc 0.9600 | elapsed 6.51s\n",
      "train epoch 14/15 | batch 203/202 | loss 0.1212 | val loss 0.2932 | acc 0.8927 | f1 0.8979 | prec 0.8986 | recall 0.8973 | roc auc 0.9517 | pr auc 0.9616 | elapsed 6.24s\n",
      "train epoch 15/15 | batch 203/202 | loss 0.1111 | val loss 0.2882 | acc 0.8948 | f1 0.9000 | prec 0.9009 | recall 0.8991 | roc auc 0.9535 | pr auc 0.9629 | elapsed 6.31s\n",
      "Complexity threshold 18\n",
      "Training 26486 #pos 14047\n",
      "Validation 6597 #pos 3500\n",
      "Test 11298 #pos 11298\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 208/207 | loss 1.5085 | val loss 1.5233 | acc 0.5842 | f1 0.5015 | prec 0.6890 | recall 0.3943 | roc auc 0.6110 | pr auc 0.6996 | elapsed 2.71s\n",
      "train epoch 01/15 | batch 208/207 | loss 1.3406 | val loss 1.1790 | acc 0.6350 | f1 0.5799 | prec 0.7446 | recall 0.4749 | roc auc 0.6899 | pr auc 0.7558 | elapsed 6.57s\n",
      "train epoch 02/15 | batch 208/207 | loss 0.9919 | val loss 0.8957 | acc 0.6944 | f1 0.6651 | prec 0.7944 | recall 0.5720 | roc auc 0.7645 | pr auc 0.8129 | elapsed 6.48s\n",
      "train epoch 03/15 | batch 208/207 | loss 0.7233 | val loss 0.6954 | acc 0.7484 | f1 0.7367 | prec 0.8281 | recall 0.6634 | roc auc 0.8233 | pr auc 0.8601 | elapsed 6.49s\n",
      "train epoch 04/15 | batch 208/207 | loss 0.5394 | val loss 0.5667 | acc 0.7938 | f1 0.7918 | prec 0.8529 | recall 0.7389 | roc auc 0.8638 | pr auc 0.8929 | elapsed 6.40s\n",
      "train epoch 05/15 | batch 208/207 | loss 0.4189 | val loss 0.4817 | acc 0.8214 | f1 0.8229 | prec 0.8686 | recall 0.7817 | roc auc 0.8912 | pr auc 0.9148 | elapsed 6.40s\n",
      "train epoch 06/15 | batch 208/207 | loss 0.3381 | val loss 0.4234 | acc 0.8410 | f1 0.8444 | prec 0.8781 | recall 0.8131 | roc auc 0.9102 | pr auc 0.9296 | elapsed 6.75s\n",
      "train epoch 07/15 | batch 208/207 | loss 0.2815 | val loss 0.3818 | acc 0.8548 | f1 0.8595 | prec 0.8828 | recall 0.8374 | roc auc 0.9237 | pr auc 0.9400 | elapsed 6.46s\n",
      "train epoch 08/15 | batch 208/207 | loss 0.2400 | val loss 0.3512 | acc 0.8678 | f1 0.8731 | prec 0.8897 | recall 0.8571 | roc auc 0.9335 | pr auc 0.9475 | elapsed 6.48s\n",
      "train epoch 09/15 | batch 208/207 | loss 0.2086 | val loss 0.3281 | acc 0.8781 | f1 0.8838 | prec 0.8942 | recall 0.8737 | roc auc 0.9408 | pr auc 0.9530 | elapsed 6.40s\n",
      "train epoch 10/15 | batch 208/207 | loss 0.1840 | val loss 0.3103 | acc 0.8837 | f1 0.8897 | prec 0.8957 | recall 0.8837 | roc auc 0.9463 | pr auc 0.9572 | elapsed 6.82s\n",
      "train epoch 11/15 | batch 208/207 | loss 0.1641 | val loss 0.2967 | acc 0.8896 | f1 0.8957 | prec 0.8985 | recall 0.8929 | roc auc 0.9506 | pr auc 0.9604 | elapsed 6.64s\n",
      "train epoch 12/15 | batch 208/207 | loss 0.1478 | val loss 0.2856 | acc 0.8946 | f1 0.9004 | prec 0.9029 | recall 0.8980 | roc auc 0.9540 | pr auc 0.9629 | elapsed 6.53s\n",
      "train epoch 13/15 | batch 208/207 | loss 0.1341 | val loss 0.2768 | acc 0.8990 | f1 0.9046 | prec 0.9067 | recall 0.9026 | roc auc 0.9566 | pr auc 0.9649 | elapsed 6.45s\n",
      "train epoch 14/15 | batch 208/207 | loss 0.1224 | val loss 0.2697 | acc 0.9015 | f1 0.9071 | prec 0.9076 | recall 0.9066 | roc auc 0.9588 | pr auc 0.9665 | elapsed 6.51s\n",
      "train epoch 15/15 | batch 208/207 | loss 0.1123 | val loss 0.2637 | acc 0.9042 | f1 0.9097 | prec 0.9102 | recall 0.9091 | roc auc 0.9605 | pr auc 0.9679 | elapsed 6.56s\n",
      "Complexity threshold 19\n",
      "Training 26945 #pos 14373\n",
      "Validation 6719 #pos 3585\n",
      "Test 10887 #pos 10887\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 212/211 | loss 1.5121 | val loss 1.5213 | acc 0.5767 | f1 0.4916 | prec 0.6844 | recall 0.3835 | roc auc 0.6145 | pr auc 0.6988 | elapsed 2.69s\n",
      "train epoch 01/15 | batch 212/211 | loss 1.3353 | val loss 1.1730 | acc 0.6261 | f1 0.5706 | prec 0.7369 | recall 0.4656 | roc auc 0.6944 | pr auc 0.7560 | elapsed 6.50s\n",
      "train epoch 02/15 | batch 212/211 | loss 0.9796 | val loss 0.8914 | acc 0.6879 | f1 0.6596 | prec 0.7888 | recall 0.5668 | roc auc 0.7667 | pr auc 0.8121 | elapsed 6.63s\n",
      "train epoch 03/15 | batch 212/211 | loss 0.7105 | val loss 0.6923 | acc 0.7467 | f1 0.7382 | prec 0.8230 | recall 0.6692 | roc auc 0.8239 | pr auc 0.8586 | elapsed 6.62s\n",
      "train epoch 04/15 | batch 212/211 | loss 0.5290 | val loss 0.5630 | acc 0.7861 | f1 0.7858 | prec 0.8438 | recall 0.7353 | roc auc 0.8638 | pr auc 0.8917 | elapsed 6.77s\n",
      "train epoch 05/15 | batch 212/211 | loss 0.4114 | val loss 0.4786 | acc 0.8154 | f1 0.8196 | prec 0.8565 | recall 0.7858 | roc auc 0.8909 | pr auc 0.9138 | elapsed 6.64s\n",
      "train epoch 06/15 | batch 212/211 | loss 0.3315 | val loss 0.4211 | acc 0.8345 | f1 0.8401 | prec 0.8668 | recall 0.8151 | roc auc 0.9096 | pr auc 0.9287 | elapsed 6.57s\n",
      "train epoch 07/15 | batch 212/211 | loss 0.2752 | val loss 0.3809 | acc 0.8522 | f1 0.8586 | prec 0.8772 | recall 0.8407 | roc auc 0.9227 | pr auc 0.9389 | elapsed 6.80s\n",
      "train epoch 08/15 | batch 212/211 | loss 0.2345 | val loss 0.3517 | acc 0.8656 | f1 0.8724 | prec 0.8840 | recall 0.8611 | roc auc 0.9322 | pr auc 0.9464 | elapsed 6.73s\n",
      "train epoch 09/15 | batch 212/211 | loss 0.2032 | val loss 0.3299 | acc 0.8750 | f1 0.8816 | prec 0.8911 | recall 0.8722 | roc auc 0.9394 | pr auc 0.9519 | elapsed 6.65s\n",
      "train epoch 10/15 | batch 212/211 | loss 0.1790 | val loss 0.3138 | acc 0.8824 | f1 0.8891 | prec 0.8951 | recall 0.8831 | roc auc 0.9446 | pr auc 0.9559 | elapsed 6.51s\n",
      "train epoch 11/15 | batch 212/211 | loss 0.1597 | val loss 0.3012 | acc 0.8878 | f1 0.8944 | prec 0.8984 | recall 0.8904 | roc auc 0.9487 | pr auc 0.9590 | elapsed 6.62s\n",
      "train epoch 12/15 | batch 212/211 | loss 0.1438 | val loss 0.2914 | acc 0.8930 | f1 0.8995 | prec 0.9016 | recall 0.8974 | roc auc 0.9518 | pr auc 0.9615 | elapsed 6.69s\n",
      "train epoch 13/15 | batch 212/211 | loss 0.1302 | val loss 0.2836 | acc 0.8951 | f1 0.9017 | prec 0.9018 | recall 0.9015 | roc auc 0.9543 | pr auc 0.9634 | elapsed 6.72s\n",
      "train epoch 14/15 | batch 212/211 | loss 0.1188 | val loss 0.2774 | acc 0.8981 | f1 0.9045 | prec 0.9041 | recall 0.9049 | roc auc 0.9563 | pr auc 0.9650 | elapsed 6.66s\n",
      "train epoch 15/15 | batch 212/211 | loss 0.1090 | val loss 0.2722 | acc 0.9004 | f1 0.9069 | prec 0.9052 | recall 0.9085 | roc auc 0.9580 | pr auc 0.9663 | elapsed 6.64s\n",
      "Complexity threshold 20\n",
      "Training 27480 #pos 14734\n",
      "Validation 6847 #pos 3672\n",
      "Test 10439 #pos 10439\n",
      "created 20 encoders with 7424 parameters each\n",
      "train epoch 00/15 | batch 216/215 | loss 1.5185 | val loss 1.4944 | acc 0.5805 | f1 0.4998 | prec 0.6932 | recall 0.3908 | roc auc 0.6214 | pr auc 0.7061 | elapsed 2.75s\n",
      "train epoch 01/15 | batch 216/215 | loss 1.3369 | val loss 1.1348 | acc 0.6346 | f1 0.5822 | prec 0.7526 | recall 0.4747 | roc auc 0.7045 | pr auc 0.7671 | elapsed 6.82s\n",
      "train epoch 02/15 | batch 216/215 | loss 0.9733 | val loss 0.8484 | acc 0.7012 | f1 0.6776 | prec 0.8040 | recall 0.5855 | roc auc 0.7797 | pr auc 0.8267 | elapsed 7.01s\n",
      "train epoch 03/15 | batch 216/215 | loss 0.6998 | val loss 0.6530 | acc 0.7618 | f1 0.7556 | prec 0.8401 | recall 0.6865 | roc auc 0.8371 | pr auc 0.8741 | elapsed 7.04s\n",
      "train epoch 04/15 | batch 216/215 | loss 0.5172 | val loss 0.5296 | acc 0.8043 | f1 0.8057 | prec 0.8617 | recall 0.7565 | roc auc 0.8755 | pr auc 0.9054 | elapsed 6.63s\n",
      "train epoch 05/15 | batch 216/215 | loss 0.4002 | val loss 0.4500 | acc 0.8293 | f1 0.8331 | prec 0.8755 | recall 0.7947 | roc auc 0.9007 | pr auc 0.9251 | elapsed 6.68s\n",
      "train epoch 06/15 | batch 216/215 | loss 0.3224 | val loss 0.3967 | acc 0.8499 | f1 0.8548 | prec 0.8879 | recall 0.8241 | roc auc 0.9177 | pr auc 0.9380 | elapsed 6.95s\n",
      "train epoch 07/15 | batch 216/215 | loss 0.2676 | val loss 0.3595 | acc 0.8652 | f1 0.8707 | prec 0.8962 | recall 0.8467 | roc auc 0.9295 | pr auc 0.9470 | elapsed 6.84s\n",
      "train epoch 08/15 | batch 216/215 | loss 0.2279 | val loss 0.3330 | acc 0.8772 | f1 0.8830 | prec 0.9027 | recall 0.8641 | roc auc 0.9378 | pr auc 0.9533 | elapsed 6.76s\n",
      "train epoch 09/15 | batch 216/215 | loss 0.1978 | val loss 0.3141 | acc 0.8846 | f1 0.8906 | prec 0.9059 | recall 0.8758 | roc auc 0.9437 | pr auc 0.9577 | elapsed 6.71s\n",
      "train epoch 10/15 | batch 216/215 | loss 0.1743 | val loss 0.2999 | acc 0.8909 | f1 0.8968 | prec 0.9102 | recall 0.8837 | roc auc 0.9481 | pr auc 0.9611 | elapsed 6.75s\n",
      "train epoch 11/15 | batch 216/215 | loss 0.1557 | val loss 0.2892 | acc 0.8951 | f1 0.9012 | prec 0.9110 | recall 0.8916 | roc auc 0.9514 | pr auc 0.9637 | elapsed 6.84s\n",
      "train epoch 12/15 | batch 216/215 | loss 0.1405 | val loss 0.2809 | acc 0.8979 | f1 0.9039 | prec 0.9123 | recall 0.8957 | roc auc 0.9540 | pr auc 0.9657 | elapsed 6.74s\n",
      "train epoch 13/15 | batch 216/215 | loss 0.1275 | val loss 0.2746 | acc 0.9002 | f1 0.9063 | prec 0.9132 | recall 0.8995 | roc auc 0.9561 | pr auc 0.9672 | elapsed 6.71s\n",
      "train epoch 14/15 | batch 216/215 | loss 0.1165 | val loss 0.2697 | acc 0.9026 | f1 0.9086 | prec 0.9145 | recall 0.9028 | roc auc 0.9577 | pr auc 0.9685 | elapsed 6.77s\n",
      "train epoch 15/15 | batch 216/215 | loss 0.1071 | val loss 0.2656 | acc 0.9026 | f1 0.9087 | prec 0.9131 | recall 0.9044 | roc auc 0.9591 | pr auc 0.9695 | elapsed 6.78s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.reasoner import ReasonerHead, EmbeddingLayer, train\n",
    "from src.utils import timestr, paramcount\n",
    "import torch as T\n",
    "from src.elpp.gen import split_dataset\n",
    "\n",
    "seed = 2022\n",
    "ts = timestr()\n",
    "\n",
    "emb_size = 32\n",
    "hidden_size = 16\n",
    "epoch_count = 15\n",
    "test_epoch_count = 10\n",
    "batch_size = 128\n",
    "\n",
    "test_artifacts = {}\n",
    "\n",
    "for complexity_threshold in range(2, 21):\n",
    "\n",
    "    print(\"Complexity threshold\", complexity_threshold)\n",
    "\n",
    "    training, validation, test = split_dataset(test_reasoners, np.random.default_rng(seed=0xbeef), complexity_threshold=complexity_threshold)\n",
    "\n",
    "    T.manual_seed(seed)\n",
    "    reasoner = best_neural_reasoner\n",
    "    encoders = [EmbeddingLayer(emb_size=emb_size, n_concepts=reasoner.n_concepts, n_roles=reasoner.n_roles) for reasoner in\n",
    "                test_reasoners]\n",
    "\n",
    "    print(f'created {len(encoders)} encoders with {paramcount(encoders[0])} parameters each')\n",
    "\n",
    "    train_logger = train(training, validation, reasoner, encoders, epoch_count=epoch_count, batch_size=batch_size, freeze_reasoner=True)\n",
    "\n",
    "    test_artifacts[complexity_threshold] = {\n",
    "        'encoders': encoders,\n",
    "        'training': training,\n",
    "        'validation': validation,\n",
    "        'test': test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = {key: {'encoders': [e.state_dict() for e in value['encoders']], 'training': value['training'], 'validation': value['validation'], 'test': value['test']} for key, value in test_artifacts.items()}\n",
    "\n",
    "with lzma.open(base_dir / 'exp2.dill.xz', 'wb') as f:\n",
    "    dill.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:24<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.reasoner import eval_batch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for complexity_threshold, components in tqdm(artifacts.items()):\n",
    "    with T.no_grad():\n",
    "        idx_te, X_te, y_te = components['test']\n",
    "        _, _, Y_te_good = eval_batch(best_neural_reasoner, components['encoders'], X_te, y_te, idx_te)\n",
    "    for i in range(len(idx_te)):\n",
    "        idx = idx_te[i]\n",
    "        axiom = X_te[i]\n",
    "        expected = y_te[i]\n",
    "        predicted = Y_te_good[i]\n",
    "        complexity = len(reasoners[idx].decode_shortest_proof(axiom[1], axiom[2]))\n",
    "        rows.append([complexity_threshold, idx, complexity, axiom, expected, int(predicted >= .5), predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complexity threshold</th>\n",
       "      <th>KB</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Axiom</th>\n",
       "      <th>Expected</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Raw predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 1, 9)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 1, 50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 1, 55)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>(0, 1, 63)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 1, 65)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445205</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>(0, 89, 44)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445206</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>(0, -2, 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445207</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>(0, -2, 56)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445208</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>(0, -2, 86)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445209</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>(0, -2, 91)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Complexity threshold  KB  Complexity        Axiom  Expected  \\\n",
       "0                          2   0           4    (0, 1, 9)         1   \n",
       "1                          2   0           6   (0, 1, 50)         1   \n",
       "2                          2   0           5   (0, 1, 55)         1   \n",
       "3                          2   0           7   (0, 1, 63)         1   \n",
       "4                          2   0           5   (0, 1, 65)         1   \n",
       "...                      ...  ..         ...          ...       ...   \n",
       "445205                    20  39          24  (0, 89, 44)         1   \n",
       "445206                    20  39          22  (0, -2, 49)         1   \n",
       "445207                    20  39          24  (0, -2, 56)         1   \n",
       "445208                    20  39          25  (0, -2, 86)         1   \n",
       "445209                    20  39          21  (0, -2, 91)         1   \n",
       "\n",
       "        Predicted  Raw predicted  \n",
       "0               1       0.762662  \n",
       "1               1       0.992152  \n",
       "2               0       0.083703  \n",
       "3               1       0.974874  \n",
       "4               0       0.440781  \n",
       "...           ...            ...  \n",
       "445205          0       0.003385  \n",
       "445206          0       0.003953  \n",
       "445207          0       0.055731  \n",
       "445208          0       0.024811  \n",
       "445209          0       0.000014  \n",
       "\n",
       "[445210 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows, columns=[\"Complexity threshold\", \"KB\", \"Complexity\", \"Axiom\", \"Expected\", \"Predicted\", \"Raw predicted\"])\n",
    "df.to_feather(base_dir / 'exp2.feather')\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasonable-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
